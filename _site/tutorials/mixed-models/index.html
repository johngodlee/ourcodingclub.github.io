<!DOCTYPE html>
<html lang="en-GB">
	<head>
    	<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Introduction to linear mixed models</title>
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- CSS -->
<link rel="stylesheet" href="/css/main.css"/>
<link rel="stylesheet" href="/css/owlcarousel/owl.carousel.css">
<link rel="stylesheet" href="/css/owlcarousel/owl.theme.default.css">

<!-- JS -->
<script src="https://use.fontawesome.com/4dd22df1f8.js"></script>
<script src="https://code.jquery.com/jquery-1.12.4.js"></script>
<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"></script>
<script src="/scripts/accordion.js"></script>
<script src="/scripts/jquery.counterup.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/waypoints/2.0.5/waypoints.min.js"></script>
<script src="/scripts/ticker.js"></script>

	</head>
	<body>
    	<header class="header">
	<div class="navigation-bar">
		<div id="navigation-container">
			
				<a class="logo" href="/">
  <img src="/assets/img/logos/logo_stack.svg" alt="Coding Club logo">
</a>

			
			<nav>
				<label for="hamburger">☰</label>
				<input type="checkbox" id="hamburger">
				<ul>
					
						
					<li class="item item-nav">
						<a href="/">Home</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/tutorials.html">Tutorials</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/course.html">Course</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/team.html">Team</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/involve.html">Get involved</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/links.html">Links</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/contact.html">Contact</a>
					</li>
					
				</ul>
			</nav>
		</div>
	</div>
</header>

			
	<div class="banner">
	
		
			<h1 style="color: $bannerNoImageColour">Introduction to linear mixed models</h1>
			
		
	
</div>




<div class="content">
	<p class="author">
		
			Created by Gabriela K Hajduk
		
		
			- last updated 10th September 2019
		
		
			by Sandra
		
	</p>
	<hr>
	<p>This workshop is aimed at people new to mixed modeling and as such, it doesn’t cover all the nuances of mixed models, but hopefully serves as a starting point when it comes to both the concepts and the code syntax in <code class="language-plaintext highlighter-rouge">R</code>. There are no equations used to keep it beginner friendly.</p>

<p><strong>Acknowledgements:</strong> First of all, thanks where thanks are due. This tutorial has been built on the tutorial written by <a href="https://twitter.com/ldbailey255" target="_blank" rel="noopener noreferrer">Liam Bailey</a>, who has been kind enough to let me use chunks of his script, as well as some of the data. Having this backbone of code made my life much, much easier, so thanks Liam, you are a star! The seemingly excessive waffling is mine.</p>

<p>If you are familiar with linear models, aware of their shortcomings and happy with their fitting, then you should be able to very quickly get through the first five sections below. Beginners might want to spend multiple sessions on this tutorial to take it all in.</p>

<p>Similarly, you will find quite a bit of explanatory text: you might choose to just skim it for now and go through the “coding bits” of the tutorial. But it will be here to help you along when you start using mixed models with your own data and you need a bit more context.</p>

<p>To get all you need for this session, <strong>go to <a href="https://github.com/ourcodingclub/CC-Linear-mixed-models" target="_blank" rel="noopener noreferrer">the repository for this tutorial</a>, click on <code class="language-plaintext highlighter-rouge">Clone/Download/Download ZIP</code> to download the files and then unzip the folder. Alternatively, fork the repository to your own Github account, clone the repository on your computer and start a version-controlled project in RStudio. For more details on how to do this, please check out our <a href="/tutorials/git/index.html">Intro to Github for Version Control tutorial</a>.</strong></p>

<p>Alternatively, you can grab the <strong>R script</strong> <a href="http://gkhajduk.d.pr/FG8/2bCpZQuj" target="_blank" rel="noopener noreferrer">here</a> and the <strong>data</strong> from <a href="http://gkhajduk.d.pr/9GPn/3nbbPoK6" target="_blank" rel="noopener noreferrer">here</a>. I might update this tutorial in the future and if I do, the latest version will be <a href="https://gkhajduk.github.io/2017-03-09-mixed-models/" target="_blank" rel="noopener noreferrer">on my website</a>.</p>

<h2 id="tutorial-sections">Tutorial Sections:</h2>

<ol>
  <li><a href="#what">What is mixed effects modelling and why does it matter?</a></li>
  <li><a href="#explore-the-data">Explore the data</a></li>
  <li><a href="#three">Fit all data in one analysis</a></li>
  <li><a href="#four">Run multiple analyses</a></li>
  <li><a href="#five">Modify the current model</a></li>
  <li>
<a href="#six">Mixed effects models</a>
    <ul>
      <li><a href="#FERE">Fixed and Random effects</a></li>
      <li><a href="#first">Let’s fit our first mixed model</a></li>
      <li>
<a href="#types">Types of random effects</a>
        <ul>
          <li><a href="#crossed">Crossed random effects</a></li>
          <li><a href="#nested">Nested random effects</a></li>
          <li><a href="#implicit">Implicit vs. explicit nesting</a></li>
        </ul>
      </li>
      <li><a href="#second">Our second mixed model</a></li>
      <li><a href="#ranslopes">Introducing random slopes</a></li>
      <li>
<a href="#presenting">Presenting your model results</a>
        <ul>
          <li><a href="#plots">Plotting model predictions</a></li>
          <li><a href="#tables">Tables</a></li>
          <li><a href="#processing">Further processing</a></li>
        </ul>
      </li>
      <li>
<a href="#extra">EXTRA: P-values and model selection</a>
        <ul>
          <li><a href="#fixedstr">Fixed effects structure</a></li>
          <li><a href="#randomstr">Random effects structure</a></li>
          <li><a href="#selection">The entire model selection</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#end">THE END</a></li>
</ol>

<h3 id="what">What is mixed effects modelling and why does it matter?</h3>

<p>Ecological and biological data are often complex and messy. We can have different <strong>grouping factors</strong> like populations, species, sites where we collect the data, etc. <strong>Sample sizes</strong> might leave something to be desired too, especially if we are trying to fit complicated models with <strong>many parameters</strong>. On top of that, our data points might <strong>not be truly independent</strong>. For instance, we might be using quadrats within our sites to collect the data (and so there is structure to our data: quadrats are nested within the sites).</p>

<p>This is why <strong>mixed models</strong> were developed, to deal with such messy data and to allow us to use all our data, even when we have low sample sizes, structured data and many covariates to fit. Oh, and on top of all that, mixed models allow us to save degrees of freedom compared to running standard linear models! Sounds good, doesn’t it?</p>

<p>We will cover only linear mixed models here, but if you are trying to “extend” your linear model, fear not: there are generalised linear mixed effects models out there, too.</p>

<h3 id="explore-the-data">Explore the data</h3>

<p>We are going to focus on a fictional study system, dragons, so that we don’t have to get too distracted with the specifics of this example. Imagine that we decided to train dragons and so we went out into the mountains and collected data on dragon intelligence (<code class="language-plaintext highlighter-rouge">testScore</code>) as a prerequisite. We sampled individuals with a range of body lengths across three sites in eight different mountain ranges. Start by loading the data and having a look at them.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">load</span><span class="p">(</span><span class="s2">"dragons.RData"</span><span class="p">)</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">dragons</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Let’s say we want to know how the body length of the dragons affects their test scores.</p>

<p>You don’t need to worry about the distribution of your <strong>explanatory</strong> variables. Have a look at the distribution of the response variable:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hist</span><span class="p">(</span><span class="n">dragons</span><span class="o">$</span><span class="n">testScore</span><span class="p">)</span><span class="w">  </span><span class="c1"># seems close to a normal distribution - good!</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-1.png" alt=""></p>

<p>It is good practice to <strong>standardise</strong> your explanatory variables before proceeding so that they have a mean of zero (“centering”) and standard deviation of one (“scaling”). It ensures that the estimated coefficients are all on the same scale, making it easier to compare effect sizes. You can use <code class="language-plaintext highlighter-rouge">scale()</code> to do that:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dragons</span><span class="o">$</span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scale</span><span class="p">(</span><span class="n">dragons</span><span class="o">$</span><span class="n">bodyLength</span><span class="p">,</span><span class="w"> </span><span class="n">center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">scale()</code> centers the data (the column mean is subtracted from the values in the column) and then scales it (the centered column values are divided by the column’s standard deviation).</p>

<p>Back to our question: is the test score affected by body length?</p>

<h3 id="three">Fit all data in one analysis</h3>

<p>One way to analyse this data would be to fit a linear model to all our data, ignoring the sites and the mountain ranges for now.</p>

<p>Fit the model with <code class="language-plaintext highlighter-rouge">testScore</code> as the response and <code class="language-plaintext highlighter-rouge">bodyLength2</code> as the predictor and have a look at the output:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">basic.lm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">basic.lm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Let’s plot the data with ggplot2.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span><span class="w">  </span><span class="c1"># load the package</span><span class="w">

</span><span class="p">(</span><span class="n">prelim_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bodyLength</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">testScore</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lm"</span><span class="p">))</span><span class="w">
  
</span></code></pre></div></div>

<p>Note that putting your entire ggplot code in brackets () creates the graph and then shows it in the plot viewer. If you don’t have the brackets, you’ve only created the object, but haven’t visualised it. You would then have to call the object such that it will be displayed by just typing <code class="language-plaintext highlighter-rouge">prelim_plot</code> after you’ve created the “prelim_plot” object.</p>

<p><img src="/assets/img/tutorials/mixed-models/mm-2.png" alt=""></p>

<p>Okay, so both from the linear model and from the plot, it seems like bigger dragons do better in our intelligence test. That seems a bit odd: size shouldn’t really affect the test scores.</p>

<p>But… are the assumptions met?</p>

<p>Plot the residuals: the red line should be nearly flat, like the dashed grey line:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">basic.lm</span><span class="p">,</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">  </span><span class="c1"># not perfect... </span><span class="w">
</span><span class="c1">## but since this is a fictional example we will go with it</span><span class="w">
</span><span class="c1">## for your own data be careful:</span><span class="w">
</span><span class="c1">## the bigger the sample size, the less of a trend you'd expect to see</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-3.png" alt=""></p>

<p>Have a quick look at the qqplot too: points should ideally fall onto the diagonal dashed line:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">basic.lm</span><span class="p">,</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w">  </span><span class="c1"># a bit off at the extremes, but that's often the case; again doesn't look too bad</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-4.png" alt=""></p>

<p>However, what about observation independence? Are our data independent?</p>

<p>We collected multiple samples from eight mountain ranges. It’s perfectly plausible that the data from within each mountain range are more similar to each other than the data from different mountain ranges: they are correlated.</p>

<p>Have a look at the data to see if above is true:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">boxplot</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">mountainRange</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w">  </span><span class="c1"># certainly looks like something is going on here</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-5.png" alt=""></p>

<p>We could also plot it and colour points by mountain range:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">colour_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bodyLength</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">testScore</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mountainRange</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_classic</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme</span><span class="p">(</span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"none"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-6.png" alt=""></p>

<p>From the above plots, it looks like our mountain ranges vary both in the dragon body length <strong>AND</strong> in their test scores. This confirms that our observations from within each of the ranges <strong>aren’t independent</strong>. We can’t ignore that: as we’re starting to see, it could lead to a completely erroneous conclusion.</p>

<p>So what do we do?</p>

<h3 id="four">Run multiple analyses</h3>

<p>We could run many separate analyses and fit a regression for each of the mountain ranges.</p>

<p>Lets have a quick look at the data split by mountain range.  We use the <code class="language-plaintext highlighter-rouge">facet_wrap</code> to do that:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">split_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">bodyLength</span><span class="p">,</span><span class="w"> </span><span class="n">testScore</span><span class="p">),</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> 
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> 
  </span><span class="n">facet_wrap</span><span class="p">(</span><span class="o">~</span><span class="w"> </span><span class="n">mountainRange</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="c1"># create a facet for each mountain range</span><span class="w">
  </span><span class="n">xlab</span><span class="p">(</span><span class="s2">"length"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> 
  </span><span class="n">ylab</span><span class="p">(</span><span class="s2">"test score"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-7.png" alt=""></p>

<p>That’s eight analyses. Oh wait, we also have different sites in each mountain range, which similarly to mountain ranges aren’t independent… So we could run an analysis for each site in each range separately.</p>

<p>To do the above, we would have to estimate a slope and intercept parameter for <strong>each regression</strong>. That’s two parameters, three sites and eight mountain ranges, which means <strong>48 parameter estimates</strong> (2 x 3 x 8 = 48)! Moreover, the sample size for each analysis would be only 20 (dragons per site).</p>

<p>This presents problems: not only are we <strong>hugely decreasing our sample size</strong>, but we are also <strong>increasing chances of a Type I Error (where you falsely reject the null hypothesis) by carrying out multiple comparisons</strong>. Not ideal!</p>

<h3 id="five">Modify the current model</h3>

<p>We want to use all the data, but account for the data coming from different mountain ranges (let’s put sites on hold for a second to make things simpler).</p>

<p>Add mountain range as a fixed effect to our <code class="language-plaintext highlighter-rouge">basic.lm</code></p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mountain.lm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">mountainRange</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">mountain.lm</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Now body length is <u>not</u> significant. But let’s think about what we are doing here for a second. The above model is estimating the difference in test scores between the mountain ranges - we can see all of them in the model output returned by <code class="language-plaintext highlighter-rouge">summary()</code>. But we are not interested in quantifying test scores for each specific mountain range: we just want to know whether body length affects test scores and we want to simply <strong>control for the variation</strong> coming from mountain ranges.</p>

<p>This is what we refer to as <strong>“random factors”</strong> and so we arrive at mixed effects models. Ta-daa!</p>

<h3 id="six">Mixed effects models</h3>

<p>A mixed model is a good choice here: it will allow us to <strong>use all the data we have</strong> (higher sample size) and <strong>account for the correlations between data</strong> coming from the sites and mountain ranges. We will also <strong>estimate fewer parameters</strong> and <strong>avoid problems with multiple comparisons</strong> that we would encounter while using separate regressions.</p>

<p>We are going to work in <code class="language-plaintext highlighter-rouge">lme4</code>, so load the package (or use <code class="language-plaintext highlighter-rouge">install.packages</code> if you don’t have <code class="language-plaintext highlighter-rouge">lme4</code> on your computer).</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">lme4</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h4 id="FERE">Fixed and random effects</h4>

<p>Let’s talk a little about the difference between <strong>fixed and random effects</strong> first. It’s important to not that this difference has little to do with the variables themselves, and a lot to do with your research question! In many cases, the same variable could be considered either a random or a fixed effect (and sometimes even both at the same time!) so always refer to your questions and hypotheses to construct your models accordingly.</p>

<div class="callout" style="">

  <h4 id="should-my-variables-be-fixed-or-random-effects">Should my variables be fixed or random effects?</h4>

  <p>In broad terms, <strong>fixed effects</strong> are variables that we expect will have an effect on the dependent/response variable: they’re what you call <strong>explanatory</strong> variables in a standard linear regression. In our case, we are interested in making conclusions about how dragon body length impacts the dragon’s test score. So body length is a fixed effect and test score is the dependent variable.</p>

  <p>On the other hand, <strong>random effects</strong> are usually <strong>grouping factors</strong> for which we are trying to control. They are always categorical, as you can’t force R to treat a continuous variable as a random effect. A lot of the time we are not specifically interested in their impact on the response variable, but we know that they might be influencing the patterns we see.</p>

  <p>Additionally, the data for our random effect is just <strong>a sample of all the possibilities</strong>: with unlimited time and funding we might have sampled every mountain where dragons live, every school in the country, every chocolate in the box), but we usually tend to generalise results to a whole population based on representative sampling. We don’t care about estimating how much better pupils in school A have done compared to pupils in school B, but we know that their respective teachers might be a reason why their scores would be different, and we’d like to know how much <em>variation</em> is attributable to this when we predict scores for pupils in school Z.</p>

  <div class="language-r highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">3</span><span class="w">
</span></code></pre></div>  </div>

</div>

<p>In our particular case, we are looking to control for the effects of mountain range. We haven’t sampled all the mountain ranges in the world (we have eight) so our data are just a sample of all the existing mountain ranges. We are not really interested in the effect of each specific mountain range on the test score: we hope our model would also be generalisable to dragons from other mountain ranges! However, we know that the test scores from within the ranges might be correlated so we want to control for that.</p>

<p>If we specifically chose eight particular mountain ranges <em>a priori</em> and we were interested in those ranges and wanted to make predictions about them, then mountain range would be fitted as a fixed effect.</p>

<div class="callout" style="">

  <h4 id="more-about-random-effects">More about random effects</h4>

  <p>Note that the golden rule is that you generally want your random effect to have <strong>at least five levels</strong>. So, for instance, if we wanted to control for the effects of dragon’s sex on intelligence, we would fit sex (a two level factor: male or female) <strong>as a fixed, not random, effect</strong>.</p>

  <p>This is, put simply, because estimating variance on few data points is very imprecise. Mathematically you <em>could</em>, but you wouldn’t have a lot of confidence in it. If you only have two or three levels, the model will struggle to partition the variance - it <em>will</em> give you an output, but not necessarily one you can trust.</p>

  <p>Finally, keep in mind that the name <em>random</em> doesn’t have much to do with <em>mathematical randomness</em>. Yes, it’s confusing. Just think about them as the <em>grouping</em> variables for now. Strictly speaking it’s all about making our models representative of our questions <strong>and getting better estimates</strong>. Hopefully, our next few examples will help you make sense of how and why they’re used.</p>

</div>

<p><strong>In the end, the big questions are:</strong> <em>what are you trying to do? What are you trying to make predictions about? What is just variation (a.k.a “noise”) that you need to control for?</em></p>

<div class="callout" style="">

  <h4 id="Further_Reading">Further reading for the keen:</h4>

  <ul>
    <li>
      <p><a href="https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/" target="_blank" rel="noopener noreferrer">Is it a fixed or random effect?</a> A useful way to think about fixed <em>vs</em>. random effects is in terms of partitioning the variation and estimating random effects with <strong>partial pooling</strong>. The description <a href="http://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode" target="_blank" rel="noopener noreferrer">here</a> is the most accessible one I could find for now and you can find more opinions in the comments under the previous link too (search for <em>pooling</em> and <em>shrinkage</em> too if you are very keen).</p>
    </li>
    <li>
      <p><a href="https://dynamicecology.wordpress.com/2015/02/05/how-many-terms-in-your-model-before-statistical-machismo/" target="_blank" rel="noopener noreferrer">How many terms? On model complexity</a></p>
    </li>
    <li>
      <p><a href="https://dynamicecology.wordpress.com/2014/12/02/why-are-your-statistical-models-more-complex-these-days/" target="_blank" rel="noopener noreferrer">More on model complexity</a></p>
    </li>
    <li>
      <p>Have a look at some of the fixed and random effects definitions gathered by Gelman in <a href="http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf" target="_blank" rel="noopener noreferrer">this paper</a> (you can also find them <a href="http://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode/4702#4702" target="_blank" rel="noopener noreferrer">here</a> if you can’t access the paper).</p>
    </li>
  </ul>

</div>

<h3 id="first">Let’s fit our first mixed model</h3>

<p>Alright! Still with me? We have a response variable, the test score and we are attempting to <strong>explain part of the variation</strong> in test score through fitting body length as a fixed effect. But the response variable has some <strong>residual variation</strong> (<em>i.e.</em> unexplained variation) associated with mountain ranges. By using random effects, we are modeling that unexplained variation through <strong>variance</strong>.</p>

<p>[Sidenote: If you are confused between variation and variance: <strong>variation</strong> is a generic word, similar to dispersion or variability; <strong>variance</strong> is a particular measure of variation; it quantifies the dispersion, if you wish.]</p>

<p>Note that <strong>our question changes slightly here</strong>: while we still want to know whether there is an association between dragon’s body length and the test score, we want to know if that association exists <strong><em>after</em></strong> controlling for the variation in mountain ranges.</p>

<p>We will fit the random effect usingv the syntax <code class="language-plaintext highlighter-rouge">(1|variableName)</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mixed.lmer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmer</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">mountainRange</span><span class="p">),</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">mixed.lmer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Once we account for the mountain ranges, it’s obvious that dragon body length doesn’t actually explain the differences in the test scores. <em>How is it obvious?</em> I hear you say?</p>

<p>Take a look at the summary output: notice how the <strong>model estimate</strong> is smaller than its associated error? That means that the effect, or slope, cannot be distinguised from zero.</p>

<p><img src="/assets/img/tutorials/mixed-models/mixed-models-output1.png" alt=""></p>

<p>Keep in mind that the random effect of the mountain range is <strong>meant to capture all the influences of mountain ranges on dragon test scores</strong> - whether we observed those influences explicitly or not, whether those influences are big or small <em>etc</em>. It could be many, many teeny-tiny influences that, when combined, affect the test scores and that’s what we are hoping to control for.</p>

<p>We can see the variance for <code class="language-plaintext highlighter-rouge">mountainRange = 339.7</code>. Mountain ranges are clearly important: they explain a lot of variation. How do we know that? We can take the variance for the <code class="language-plaintext highlighter-rouge">mountainRange</code> and divide it by the total variance:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="m">339.7</span><span class="o">/</span><span class="p">(</span><span class="m">339.7</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">223.8</span><span class="p">)</span><span class="w">  </span><span class="c1"># ~60 %</span><span class="w">
</span></code></pre></div></div>

<p>So the differences between mountain ranges explain ~60% of the variance that’s “left over” <em>after</em> the variance explained by our fixed effects.</p>

<div class="callout" style="">

  <h4 id="more-reading-on-random-effects">More reading on random effects</h4>

  <p>Still confused about interpreting random effects? These links have neat demonstrations and explanations:</p>

  <p><a href="https://www.r-bloggers.com/making-sense-of-random-effects/" target="_blank" rel="noopener noreferrer">R-bloggers: Making sense of random effects</a></p>

  <p><a href="https://www.theanalysisfactor.com/understanding-random-effects-in-mixed-models/" target="_blank" rel="noopener noreferrer">The Analysis Factor: Understanding random effects in mixed models</a></p>

  <p><a href="http://www.bodowinter.com/tutorial/bw_LME_tutorial.pdf" target="_blank" rel="noopener noreferrer">Bodo Winter: A very basic tutorial for performing linear mixed effect analyses</a></p>

</div>

<p>As always, it’s good practice to have a look at the plots to check our assumptions:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">mixed.lmer</span><span class="p">)</span><span class="w">  </span><span class="c1"># looks alright, no patterns evident</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-8.png" alt=""></p>

<p>and <code class="language-plaintext highlighter-rouge">qqplot</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">qqnorm</span><span class="p">(</span><span class="n">resid</span><span class="p">(</span><span class="n">mixed.lmer</span><span class="p">))</span><span class="w">
</span><span class="n">qqline</span><span class="p">(</span><span class="n">resid</span><span class="p">(</span><span class="n">mixed.lmer</span><span class="p">))</span><span class="w">  </span><span class="c1"># points fall nicely onto the line - good!</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-9.png" alt=""></p>

<h4 id="types">Types of random effects</h4>

<p>Before we go any further, let’s review the syntax above and chat about crossed and nested random effects. It’s useful to get those clear in your head.</p>

<p><strong>Reminder</strong>: a factor is just any categorical independent variable.</p>

<p>Above, we used <code class="language-plaintext highlighter-rouge">(1|mountainRange)</code> to fit our random effect. Whatever is on the right side of the <code class="language-plaintext highlighter-rouge">|</code> operator is a factor and referred to as a “grouping factor” for the term.</p>

<p><strong>Random effects (factors) can be crossed or nested</strong> - it depends on the relationship between the variables. Let’s have a look.</p>

<h5 id="crossed">Crossed random effects</h5>

<p>Be careful with the nomenclature. There are <strong>“hierarchical linear models”</strong> (HLMs) or <strong>“multilevel models”</strong> out there, but while all HLMs are mixed models, <strong>not all mixed models are hierarchical</strong>. That’s because you can have <strong>crossed (or partially crossed) random factors</strong> that do not represent levels in a hierarchy.</p>

<p>Think for instance about our study where you monitor dragons (subject) across different mountain ranges (context) and imagine that we collect <strong>multiple observations per dragon</strong> by giving it the test multiple times (and risking <strong>pseudoreplication</strong> - but more on that later). Since our dragons can fly, it’s easy to imagine that <strong>we might observe the same dragon across different mountain ranges</strong>, but also that we might not see all the dragons visiting all of the mountain ranges. Therefore, we can potentially observe every dragon in every mountain range (<strong>crossed</strong>) or at least observe some dragons across some of the mountain ranges (<strong>partially crossed</strong>). We would then fit the identity of the dragon and mountain range as (partially) crossed random effects.</p>

<p>Let’s repeat with another example: an effect is <strong>(fully) crossed</strong> when <em>all the subjects</em> have experienced <em>all the levels</em> of that effect. For instance, if you had a fertilisation experiment on seedlings growing in a seasonal forest and took repeated measurements over time (say 3 years) in each season, you may want to have a crossed factor called <code class="language-plaintext highlighter-rouge">season</code> (Summer1, Autumn1, Winter1, Spring1, Summer2, …, Spring3), i.e. a factor for each season of each year. This grouping factor would account for the fact that all plants in the experiment, regardless of the fixed (treatment) effect (i.e. fertilised or not), may have experienced a very hot summer in the second year, or a very rainy spring in the third year, and those conditions could cause interference in the expected patterns. You don’t even need to have associated climate data to account for it! You just know that all observations from spring 3 may be more similar to each other because they experienced the same environmental quirks rather than because they’re responding to your treatment.</p>

<p>If this sounds confusing, not to worry - <code class="language-plaintext highlighter-rouge">lme4</code> handles partially and fully crossed factors well. Now, let’s look at <strong>nested</strong> random effects and how to specify them.</p>

<h4 id="nested">Nested random effects</h4>

<p>If you’re not sure what nested random effects are, think of those Russian nesting dolls. We’ve already hinted that we call these models <strong>hierarchical</strong>: there’s often an element of scale, or sampling stratification in there.</p>

<p>Take our fertilisation experiment example again; let’s say you have 50 seedlings in each bed, with 10 control and 10 experimental beds. That’s 1000 seedlings altogether. And let’s say you went out collecting once in each season in each of the 3 years. On each plant, you measure the length of 5 leaves. That’s….(lots of maths)…5 leaves x 50 plants x 20 beds x 4 seasons x 3 years….. 60 000 measurements!</p>

<p>But if you were to run the analysis using a simple linear regression, eg. <code class="language-plaintext highlighter-rouge">leafLength ~ treatment </code>, you would be committing the crime (!!) of <strong>pseudoreplication</strong>, or massively increasing your sampling size by using non-independent data. With a sample size of 60,000 you would almost certainly get a “significant” effect of treatment which may have no ecological meaning at all. And it violates the <strong>assumption of independance of observations</strong> that is central to linear regression.</p>

<p>This is where our nesting dolls come in; leaves within a plant and plants within a bed may be more similar to each other (e.g. for genetic and environmental reasons, respectively). You could therefore add a random effect structure that accounts for this nesting:</p>

<p><code class="language-plaintext highlighter-rouge">leafLength ~ treatment + (1|Bed/Plant/Leaf)</code></p>

<p>This way, the model will account for non independence in the data: the same leaves have been sampled repeatedly, multiple leaves were measured on an individual, and plants are grouped into beds which may receive different amounts of sun, etc.</p>

<p>What about the crossed effects we mentioned earlier? If all the leaves have been measured in all seasons, then your model would become something like:</p>

<p><code class="language-plaintext highlighter-rouge">leafLength ~ treatment + (1|Bed/Plant/Leaf) + (1|Season)</code></p>

<p>Phew!</p>

<div class="callout" style="">

  <h4 id="implicit">Implicit <em>vs</em>. explicit nesting</h4>

  <p>To make things easier for yourself, code your data properly and <strong>avoid implicit nesting</strong>.</p>

  <p>To tackle this, let’s look at another aspect of our study: we collected the data on dragons not only across multiple mountain ranges, but also across several sites within those mountain ranges. If you don’t remember have another look at the data:</p>

  <div class="language-r highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="n">head</span><span class="p">(</span><span class="n">dragons</span><span class="p">)</span><span class="w">  </span><span class="c1"># we have site and mountainRange</span><span class="w">
</span><span class="n">str</span><span class="p">(</span><span class="n">dragons</span><span class="p">)</span><span class="w">  </span><span class="c1"># we took samples from three sites per mountain range and eight mountain ranges in total</span><span class="w">
</span></code></pre></div>  </div>

  <p>Just like we did with the mountain ranges, we have to assume that data collected within our sites might be <strong>correlated</strong> and so we should include sites as <strong>an additional random effect</strong> in our model.</p>

  <p>Our site variable is a three-level factor, with sites called <code class="language-plaintext highlighter-rouge">a</code>, <code class="language-plaintext highlighter-rouge">b</code> and <code class="language-plaintext highlighter-rouge">c</code>. The nesting of the site within the mountain range is <strong>implicit</strong> - our sites are meaningless without being assigned to specific mountain ranges, i.e. there is nothing linking site <code class="language-plaintext highlighter-rouge">b</code> of the <code class="language-plaintext highlighter-rouge">Bavarian</code> mountain range with site <code class="language-plaintext highlighter-rouge">b</code> of the <code class="language-plaintext highlighter-rouge">Central</code> mountain range. To avoid future confusion we should create a new variable that is <strong>explicitly nested</strong>. Let’s call it <code class="language-plaintext highlighter-rouge">sample</code>:</p>

  <div class="language-r highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="n">dragons</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">within</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">factor</span><span class="p">(</span><span class="n">mountainRange</span><span class="o">:</span><span class="n">site</span><span class="p">))</span><span class="w">
</span></code></pre></div>  </div>

  <p>Now it’s obvious that we have 24 samples (8 mountain ranges x 3 sites) and not just 3: our <code class="language-plaintext highlighter-rouge">sample</code> is a 24-level factor and we should use that instead of using <code class="language-plaintext highlighter-rouge">site</code> in our models: each site belongs to a specific mountain range.</p>

  <p><strong>To sum up:</strong> for <strong>nested random effects</strong>, the factor appears <strong>ONLY</strong> within a particular level of another factor (each site belongs to a specific mountain range and only to that range); for <strong>crossed effects</strong>, a given factor appears in more than one level of another factor (dragons appearing within more than one mountain range). <strong>Or you can just remember that if your random effects aren’t nested, then they are crossed!</strong></p>

</div>

<h3 id="second">Our second mixed model</h3>

<p>Based on the above, using following specification would be <strong>**wrong**</strong>, as it would imply that there are only three sites with observations at <em>each</em> of the 8 mountain ranges (crossed):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mixed.WRONG</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmer</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">mountainRange</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">site</span><span class="p">),</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w">  </span><span class="c1"># treats the two random effects as if they are crossed</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">mixed.WRONG</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mixed-models-output-wrong.png" alt=""></p>

<p>But we can go ahead and fit a new model, one that takes into account both the differences between the mountain ranges, as well as the differences between the sites within those mountain ranges by using our <code class="language-plaintext highlighter-rouge">sample</code> variable.</p>

<p>Our question gets <strong>adjusted slightly again</strong>: Is there an association between body length and intelligence in dragons <strong><em>after</em></strong> controlling for variation in mountain ranges and sites within mountain ranges?</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mixed.lmer2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmer</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">mountainRange</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">sample</span><span class="p">),</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w">  </span><span class="c1"># the syntax stays the same, but now the nesting is taken into account</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">mixed.lmer2</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mixed-models-output-right.png" alt="correct factor nesting"></p>

<p>Here, we are trying to account for <strong>all the mountain-range-level</strong> <em>and</em> <strong>all the site-level influences</strong> and we are hoping that our random effects have soaked up all these influences so we can control for them in the model.</p>

<p>For the record, you could also use the below syntax, and you will often come across it if you read more about mixed models:</p>

<p><code class="language-plaintext highlighter-rouge">(1|mountainRange/site)</code>  or even
<code class="language-plaintext highlighter-rouge">(1|mountainRange) + (1|mountainRange:site)</code></p>

<p>However, it is advisable to set out your variables properly and make sure nesting is stated explicitly within them, that way you don’t have to remember to specify the nesting.</p>

<p>Let’s plot this again - visualising what’s going on is always helpful. You should be able to see eight mountain ranges with three sites (different colour points) within them, with a line fitted through each site.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">mm_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bodyLength</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">testScore</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">site</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">facet_wrap</span><span class="p">(</span><span class="o">~</span><span class="n">mountainRange</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">   </span><span class="c1"># a panel for each mountain range</span><span class="w">
      </span><span class="n">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme_classic</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_line</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">mixed.lmer2</span><span class="p">)),</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">  </span><span class="c1"># adding predicted line from mixed model </span><span class="w">
      </span><span class="n">theme</span><span class="p">(</span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
            </span><span class="n">panel.spacing</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">unit</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="s2">"lines"</span><span class="p">))</span><span class="w">  </span><span class="c1"># adding space between panels</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-10.png" alt=""></p>

<h3 id="ranslopes">Introducing random slopes</h3>

<p>You might have noticed that all the lines on the above figure are parallel: that’s because so far, we have only fitted <strong>random-intercept models</strong>. A random-intercept model allows the intercept to vary for each level of the random effects, but keeps the slope constant among them. So in our case, using this model means that we expect dragons in all mountain ranges to exhibit the same relationship between body length and intelligence (fixed slope), although we acknowledge that some populations may be smarter or dumber to begin with (random intercept).</p>

<p>Now, in the life sciences, we perhaps more often assume that not all populations would show the exact same relationship, for instance if your study sites/populations are very far apart and have some relatively important environmental, genetic, etc differences. Therefore, we often want to fit a <strong>random-slope and random-intercept model</strong>. Maybe the dragons in a very cold vs a very warm mountain range have evolved different body forms for heat conservation and may therefore be smart even if they’re smaller than average.</p>

<p>We only need to make one change to our model to allow for random slopes as well as intercept, and that’s adding the fixed variable into the random effect brackets:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mixed.ranslope</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmer</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">bodyLength2</span><span class="o">|</span><span class="n">mountainRange</span><span class="o">/</span><span class="n">site</span><span class="p">),</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">)</span><span class="w"> 

</span><span class="n">summary</span><span class="p">(</span><span class="n">mixed.slope</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Here, we’re saying, let’s model the intelligence of dragons as a function of body length, knowing that populations have different intelligence baselines <strong>and</strong> that the relationship may vary among populations.</p>

<p>Let’s see that with a quick plot (we’ll plot predictions in more detail in the next section). Notice how the slopes for the different sites and mountain ranges are not parallel anymore?</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### plot</span><span class="w">
</span><span class="p">(</span><span class="n">mm_plot</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggplot</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bodyLength</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">testScore</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">site</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">facet_wrap</span><span class="p">(</span><span class="o">~</span><span class="n">mountainRange</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">   </span><span class="c1"># a panel for each mountain range</span><span class="w">
      </span><span class="n">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">theme_classic</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
      </span><span class="n">geom_line</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">mixed.ranslope</span><span class="p">)),</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">  </span><span class="c1"># adding predicted line from mixed model </span><span class="w">
      </span><span class="n">theme</span><span class="p">(</span><span class="n">legend.position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"none"</span><span class="p">,</span><span class="w">
            </span><span class="n">panel.spacing</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">unit</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="s2">"lines"</span><span class="p">))</span><span class="w">  </span><span class="c1"># adding space between panels</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-ranslopes.png" alt=""></p>

<p><strong>Well done for getting here!</strong> You have now fitted random-intercept and random-slopes, random-intercept mixed models and you know how to account for hierarchical and crossed random effects. You saw that failing to account for the correlation in data might lead to misleading results - it seemed that body length affected the test score until we accounted for the variation coming from mountain ranges. We can see now that body length doesn’t influence the test scores - great! We can pick smaller dragons for any future training - smaller ones should be more manageable!</p>

<p>If you are particularly keen, the next section gives you a few options when it comes to <strong>presenting your model results</strong> and in the last “extra” section you  can learn about the <strong>model selection conundrum</strong>. There is just a little bit more code there to get through if you fancy those.</p>

<h4 id="presenting">Presenting your model results</h4>

<p>Once you get your model, you have to <strong>present</strong> it in a nicer form.</p>

<h4 id="plots">Plotting model predictions</h4>

<p>Often you will want to visualise your model as a regression line with some error around it, just like you would a simple linear model. However, <code class="language-plaintext highlighter-rouge">ggplot2</code> stats options are not designed to estimate mixed-effect model objects correctly, so we will use the <code class="language-plaintext highlighter-rouge">ggeffects</code> package to help us draw the plots.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">ggeffects</span><span class="p">)</span><span class="w">  </span><span class="c1"># install the package first if you haven't already, then load it</span><span class="w">

</span><span class="c1"># Extract the prediction data frame</span><span class="w">
</span><span class="n">pred.mm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ggpredict</span><span class="p">(</span><span class="n">mixed.lmer2</span><span class="p">,</span><span class="w"> </span><span class="n">terms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"bodyLength2"</span><span class="p">))</span><span class="w">  </span><span class="c1"># this gives overall predictions for the model</span><span class="w">

</span><span class="c1"># Plot the predictions </span><span class="w">

</span><span class="p">(</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pred.mm</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> 
   </span><span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predicted</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">          </span><span class="c1"># slope</span><span class="w">
   </span><span class="n">geom_ribbon</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predicted</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">std.error</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">predicted</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std.error</span><span class="p">),</span><span class="w"> 
               </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lightgrey"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">  </span><span class="c1"># error band</span><span class="w">
   </span><span class="n">geom_point</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">,</span><span class="w">                      </span><span class="c1"># adding the raw data (scaled values)</span><span class="w">
              </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bodyLength2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">testScore</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mountainRange</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w"> 
   </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Body Length (indexed)"</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Test Score"</span><span class="p">,</span><span class="w"> 
        </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Body length does not affect intelligence in dragons"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> 
   </span><span class="n">theme_minimal</span><span class="p">()</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mixed-models-ggpredict1.jpeg" alt=""></p>

<p>What if you want to visualise how the relationships vary according to different levels of random effects? You can specify <code class="language-plaintext highlighter-rouge">type = "re"</code> (for “random effects”) in the <code class="language-plaintext highlighter-rouge">ggpredict()</code> function, and add the random effect name to the <code class="language-plaintext highlighter-rouge">terms</code> argument.</p>

<p>We also demonstrate a way to plot the graph quicker with the <code class="language-plaintext highlighter-rouge">plot()</code> function of <code class="language-plaintext highlighter-rouge">ggEffects</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ggpredict(mixed.lmer2, terms = c("bodyLength2", "mountainRange"), type = "re") %&gt;% 
   plot() +
   labs(x = "Body Length", y = "Test Score", title = "Effect of body size on intelligence in dragons") + 
   theme_minimal()
</code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mixed-models-ggpredict2.jpeg" alt=""></p>

<p>You can clearly see the random intercepts and fixed slopes from this graph. When assessing the quality of your model, it’s always a good idea to look at the raw data, the summary output, and the predictions all together to make sure you understand what is going on (and that you have specified the model correctly).</p>

<p>Another way to visualise mixed model results, if you are interested in showing the variation among levels of your random effects, is to plot the <em>departure from the overall model estimate</em> for intercepts - and slopes, if you have a random slope model:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">sjPlot</span><span class="p">)</span><span class="w">

</span><span class="c1"># Visualise random effects </span><span class="w">
</span><span class="p">(</span><span class="n">re.effects</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">plot_model</span><span class="p">(</span><span class="n">mixed.ranslope</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"re"</span><span class="p">,</span><span class="w"> </span><span class="n">show.values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">

</span><span class="c1"># show summary</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">mixed.ranslope</span><span class="p">)</span><span class="w">

</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/sjplot.png" alt=""></p>

<p><strong>Careful here!</strong> The values you see are <strong>NOT</strong> <em>actual</em> values, but rather the <em>difference</em> between the general intercept or slope value found in your model summary and the estimate for this <em>specific level</em> of random effect. For instance, the relationship for dragons in the Maritime mountain range would have a slope of <code class="language-plaintext highlighter-rouge">(-2.91 + 0.67) = -2.24</code> and an intercept of <code class="language-plaintext highlighter-rouge">(20.77 + 51.43) = 72.20</code>.</p>

<p>If you are looking for more ways to create plots of your results, check out <code class="language-plaintext highlighter-rouge">dotwhisker</code> and <a href="https://cran.r-project.org/web/packages/dotwhisker/vignettes/dotwhisker-vignette.html" target="_blank" rel="noopener noreferrer">this tutorial</a>.</p>

<h4 id="tables">Tables</h4>

<p>For <code class="language-plaintext highlighter-rouge">lme4</code>, if you are looking for a table, I’d recommend that you have a look at the <code class="language-plaintext highlighter-rouge">stargazer</code> package.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">stargazer</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">stargazer</code>is very nicely annotated and there are lots of resources (e.g. <a href="https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf" target="_blank" rel="noopener noreferrer">this</a>) out there and a <a href="http://jakeruss.com/cheatsheets/stargazer.html" target="_blank" rel="noopener noreferrer">great cheat sheet</a> so I won’t go into too much detail, as I’m confident you will find everything you need.</p>

<p>Here is a quick example - simply plug in your model name, in this case <code class="language-plaintext highlighter-rouge">mixed.lmer2</code> into the <code class="language-plaintext highlighter-rouge">stargazer</code> function. I set <code class="language-plaintext highlighter-rouge">type</code> to <code class="language-plaintext highlighter-rouge">"text"</code> so that you can see the table in your console. I usually tweak the table like this until I’m happy with it and then export it using  <code class="language-plaintext highlighter-rouge">type = "latex"</code>, but <code class="language-plaintext highlighter-rouge">"html"</code> might be more useful for you if you are not a LaTeX user.</p>

<p>If you are keen, explore this table a little further - what would you change? What would you get rid off?</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stargazer</span><span class="p">(</span><span class="n">mixed.lmer2</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"text"</span><span class="p">,</span><span class="w">
          </span><span class="n">digits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w">
          </span><span class="n">star.cutoffs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="m">0.01</span><span class="p">,</span><span class="w"> </span><span class="m">0.001</span><span class="p">),</span><span class="w">
          </span><span class="n">digit.separator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">""</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mixed-models/mm-tab.png" alt=""></p>

<h4 id="processing">Further processing</h4>

<p>If you’d like to be able <strong>to do more with your model results</strong>, for instance process them further, collate model results from multiple models or plot, them have a look at the <code class="language-plaintext highlighter-rouge">broom</code> package. This <a href="http://varianceexplained.org/r/broom-intro/" target="_blank" rel="noopener noreferrer">tutorial</a> is a great start.</p>

<h4 id="extra">EXTRA: P-values and model selection</h4>

<p>Please be <strong>very, very careful</strong> when it comes to model selection. Focus on your <strong>question</strong>, don’t just plug in and drop variables from a model haphazardly until you make something “significant”. Always choose variables based on biology/ecology: I might use model selection to check a couple of non-focal parameters, but I keep the “core” of the model untouched in most cases. <strong>Define your goals and questions and focus on that.</strong> Also, don’t just put all possible variables in (i.e. don’t <strong>overfit</strong>). Remember that as a rule of thumb, <strong>you need 10 times more data than parameters</strong> you are trying to estimate.</p>

<p>For more info on overfitting check out this <a href="/2017/02/28/modelling.html">tutorial</a>.</p>

<h4 id="fixedstr">Fixed effects structure</h4>

<p><strong>Before we start, again: think twice before trusting model selection!</strong></p>

<p>Most of you are probably going to be predominantly interested in your fixed effects, so let’s start here. <code class="language-plaintext highlighter-rouge">lme4</code> doesn’t spit out p-values for the parameters by default. This is a conscious choice made by the authors of the package, as there are many problems with p-values (I’m sure you are aware of the debates!).</p>

<p>You will inevitably look for a way to assess your model though so here are a few solutions on how to go about hypothesis testing in linear mixed models (LMMs):</p>

<p><strong>From worst to best:</strong></p>

<ul>
  <li>Wald Z-tests</li>
  <li>Wald t-tests (but LMMs need to be balanced and nested)</li>
  <li>Likelihood ratio tests (via <code class="language-plaintext highlighter-rouge">anova()</code> or <code class="language-plaintext highlighter-rouge">drop1()</code>)</li>
  <li>
<code class="language-plaintext highlighter-rouge">MCMC</code> or parametric bootstrap confidence intervals</li>
</ul>

<p>See <a href="http://stats.stackexchange.com/questions/95054/how-to-get-an-overall-p-value-and-effect-size-for-a-categorical-factor-in-a-mi" target="_blank" rel="noopener noreferrer">this link</a> for more information and further reading.</p>

<p>I think that <code class="language-plaintext highlighter-rouge">MCMC</code> and bootstrapping are a bit out of our reach for this workshop so let’s have a quick go at <strong>likelihood ratio tests</strong> using <code class="language-plaintext highlighter-rouge">anova()</code>. With large sample sizes, p-values based on the likelihood ratio are generally considered okay. <strong>NOTE:</strong> With small sample sizes, you might want to look into deriving p-values using the Kenward-Roger or Satterthwaite approximations (for <code class="language-plaintext highlighter-rouge">REML</code> models). Check out the <code class="language-plaintext highlighter-rouge">pbkrtest</code> package.</p>

<p>Fit the models, a full model and a reduced model in which we dropped our fixed effect (<code class="language-plaintext highlighter-rouge">bodyLength2</code>):</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">full.lmer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmer</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">bodyLength2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">mountainRange</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">sample</span><span class="p">),</span><span class="w"> 
				  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">REML</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">reduced.lmer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lmer</span><span class="p">(</span><span class="n">testScore</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">mountainRange</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">|</span><span class="n">sample</span><span class="p">),</span><span class="w"> 
					     </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dragons</span><span class="p">,</span><span class="w"> </span><span class="n">REML</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Compare them:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">anova</span><span class="p">(</span><span class="n">reduced.lmer</span><span class="p">,</span><span class="w"> </span><span class="n">full.lmer</span><span class="p">)</span><span class="w">  </span><span class="c1"># the two models are not significantly different</span><span class="w">
</span></code></pre></div></div>

<p>Notice that we have fitted our models with <code class="language-plaintext highlighter-rouge">REML = FALSE</code>.</p>

<p><strong>REML</strong> stands for <strong>restricted (or “residual”) maximum likelihood</strong> and it is the default parameter estimation criterion for linear mixed models. As you probably guessed, <strong>ML</strong> stands for  <strong>maximum likelihood</strong> - you can set  <code class="language-plaintext highlighter-rouge">REML = FALSE</code> in your call to <code class="language-plaintext highlighter-rouge">lmer</code> to use ML estimates. However, <strong>ML estimates are known to be biased</strong> and with REML being usually less biased, <strong>REML estimates of variance components are generally preferred.</strong> This is why in our previous models we skipped setting <code class="language-plaintext highlighter-rouge">REML</code> - we just left it as default (i.e. <code class="language-plaintext highlighter-rouge">REML = TRUE</code>).</p>

<p><strong>REML</strong> assumes that the fixed effects structure is correct. You <strong>should use maximum likelihood when comparing models with different fixed effects</strong>, as <strong>ML</strong> doesn’t rely on the coefficients of the fixed effects - and that’s why we are refitting our full and reduced models above with the addition of <code class="language-plaintext highlighter-rouge">REML = FALSE</code> in the call.</p>

<p>Even though you <strong>use ML to compare models</strong>, you should <strong>report parameter estimates from your final “best” REML model</strong>, as ML may underestimate variance of the random effects.</p>

<p><strong>NOTE 2:</strong> Models can also be compared using the <code class="language-plaintext highlighter-rouge">AICc</code> function from the <code class="language-plaintext highlighter-rouge">AICcmodavg</code> package. The Akaike Information Criterion (AIC) is a measure of model quality. AICc corrects for bias created by small sample size when estimating AIC. Generally, if models are within 2 AICc units of each other they are very similar. Within 5 units they are quite similar, over 10 units difference and you can probably be happy with the model with lower AICc. As with p-values though, there is no “hard line” that’s always correct.</p>

<p><strong>NOTE 3:</strong> There isn’t really an agreed upon way of dealing with the variance from the random effects in mixed models when it comes to assessing significance. Both <strong>p-values</strong> and <strong>effect sizes</strong> have issues, although from what I gather, p-values seem to cause more disagreement than effect sizes, at least in the R community.</p>

<h4 id="randomstr">Random effects structure</h4>

<p>Now you might wonder about selecting your random effects. In general, I’d advise you to think about your <strong>experimental design, your system and data collected, as well as your questions</strong>.</p>

<p>If your random effects are there to deal with <strong>pseudoreplication</strong>, then it doesn’t really matter whether they are “significant” or not: they <strong>are part of your design</strong> and have to be included. Imagine we tested our dragons multiple times - we then <em>have to</em> fit dragon identity as a random effect.</p>

<p>On the other hand, if you are trying to account for other variability that you think might be important, it becomes a bit harder. Imagine we measured the mass of our dragons over their lifespans (let’s say 100 years). We might then want to fit year as a random effect to account for any temporal variation - maybe some years were affected by drought, the resources were scarce and so dragon mass was negatively impacted. Year would definitely be a sensible random effect, although strictly speaking not a must.</p>

<p>When it comes to such random effects you can use <strong>model selection</strong> to help you decide what to keep in. Following Zuur’s advice, we <strong>use <code class="language-plaintext highlighter-rouge">REML</code> estimators for comparison of models with different random effects</strong> (we keep fixed effects constant). (Zuur: “Two models with nested random structures cannot be done with ML because the estimators for the variance terms are biased.” )</p>

<p><strong>NOTE:</strong> Do <strong>NOT</strong> vary random and fixed effects at the same time - either deal with your random effects structure or with your fixed effects structure at any given point.</p>

<p><strong>NOTE 2:</strong> Do <strong>NOT</strong> compare <code class="language-plaintext highlighter-rouge">lmer</code> models with <code class="language-plaintext highlighter-rouge">lm</code> models (or <code class="language-plaintext highlighter-rouge">glmer</code> with <code class="language-plaintext highlighter-rouge">glm</code>).</p>

<h4 id="selection">Entire model selection</h4>

<p>A few notes on the process of model selection. There are two ways here: (i) <strong>“top-down”</strong>, where you start with a complex model and gradually reduce it, and (ii) <strong>“step up”</strong>, where you start with a simple model and add new variables to it. Unfortunately, you might arrive at different final models by using those strategies and so you need to be careful.</p>

<p>The model selection process recommended by Zuur <em>et al.</em> (2009) is a top-down strategy and goes as follows:</p>

<ol>
  <li>fit a <strong>full model</strong> (he even recommends “beyond optimal” i.e. more complex than you’d expect or want it to be)</li>
  <li>sort out the <strong>random effects structure</strong> (use <code class="language-plaintext highlighter-rouge">REML</code> likelihoods or <code class="language-plaintext highlighter-rouge">REML</code> AIC or BIC)</li>
  <li>sort out <strong>fixed effects structure</strong> (either use <code class="language-plaintext highlighter-rouge">REML</code> the F-statistic or the t-statistic or compare nested <code class="language-plaintext highlighter-rouge">ML</code> models - keep your random effects constant)</li>
  <li>once you arrive at the <strong>final model present it using <code class="language-plaintext highlighter-rouge">REML</code> estimation</strong>
</li>
</ol>

<p><strong>NOTE:</strong> At the risk of sounding like a broken record: I think it’s best to decide on what your model is based on biology/ecology/data structure <em>etc</em>. than through following model selection blindly. Additionally, just because something is non-significant doesn’t necessarily mean you should always get rid of it.</p>

<h3 id="end">THE END</h3>

<p><strong>Well done for getting through this!</strong> As you probably gather, mixed effects models can be a bit tricky and often there isn’t much consensus on the best way to tackle something within them. The coding bit is actually the (relatively) easy part here. Be mindful of what you are doing, prepare the data well and things should be alright.</p>


	<div class="survey">
	<hr>
	<hr>
	
		<h4><a href="" target="_blank">We would love to hear your feedback, please fill out our survey!</a></h4>
	
	<h4>Contact us with any questions on <a href="mailto:ourcodingclub@gmail.com?Subject=Tutorial%20question" target="_top">ourcodingclub@gmail.com</a>
</h4>
	<br>
	<h3>Related tutorials:</h3>
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
		
	
	<br>
	<h3>Subscribe to our mailing list:</h3>

	<div class="container">
		<div class="block">
			<!-- subscribe form start -->
			<div class="form-group">
				<form action="https://getsimpleform.com/messages?form_api_token=de1ba2f2f947822946fb6e835437ec78" method="post">
					<div class="form-group">
						<input type="text" class="form-control" name="Email" placeholder="Email" required>
					</div>
					<div>
            			<button class="btn btn-default" type="submit">Subscribe</button>
        			</div>
            	</form>
			</div>
		</div>
	</div>
</div>

</div>

    	<footer class="footer">
	<hr>
	<div class="footer-container">
    	<ul class="footer-link-list">
        	<li><a href="/tutorials">Tutorials</a></li>
        	<li><a href="/team">About Us</a></li>
        	<li><a href="/contact">Contact us</a></li>
	    	<li><a href="https://twitter.com/our_codingclub" target="_blank" rel="noopener noreferrer">Follow us on Twitter</a></li>
    	</ul>
    	<div class="footer-text">
			<p>We are happy for people to use and further develop our tutorials - please give credit to Coding Club by linking to <a href="https://ourcodingclub.github.io/" target="_blank" rel="noopener noreferrer">our website</a>. We are also happy to discuss possible collaborations, so get in touch at <b>ourcodingclub@gmail.com</b></p>
    		<p>See our <a href="/terms">Terms of Use</a> and our <a href="/privacy">Data Privacy policy</a>.</p>
			<p>This work is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer">Creative Commons Attribution-ShareAlike 4.0 International License</a></p>
			<a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer"><img class="license" src="https://licensebuttons.net/l/by-sa/4.0/80x15.png" alt="CC-by-sa-4.0"></a>
    	</div>
    </div>
</footer>

<!-- JS -->
<script src="/scripts/owl.carousel.js"></script>
<script src="/scripts/owl.carousel-init.js"></script>
<script src="/scripts/reveal.js"></script>


	
	</body>
</html>
