<!DOCTYPE html>
<html lang="en-GB">
	<head>
    	<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Meta-analysis for biologists using MCMCglmm</title>
<meta name="description" content="">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- CSS -->
<link rel="stylesheet" href="/css/main.css"/>
<link rel="stylesheet" href="/css/owlcarousel/owl.carousel.css">
<link rel="stylesheet" href="/css/owlcarousel/owl.theme.default.css">

<!-- JS -->
<script src="https://use.fontawesome.com/4dd22df1f8.js"></script>
<script src="https://code.jquery.com/jquery-1.12.4.js"></script>
<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"></script>
<script src="/scripts/accordion.js"></script>
<script src="/scripts/jquery.counterup.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/waypoints/2.0.5/waypoints.min.js"></script>
<script src="/scripts/ticker.js"></script>

	</head>
	<body>
    	<header class="header">
	<div class="navigation-bar">
		<div id="navigation-container">
			
				<a class="logo" href="/">
  <img src="/assets/img/logos/logo_stack.svg" alt="Coding Club logo">
</a>

			
			<nav>
				<label for="hamburger">☰</label>
				<input type="checkbox" id="hamburger">
				<ul>
					
						
					<li class="item item-nav">
						<a href="/">Home</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/tutorials.html">Tutorials</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/course.html">Course</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/team.html">Team</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/involve.html">Get involved</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/links.html">Links</a>
					</li>
					
						
					<li class="item item-nav">
						<a href="/contact.html">Contact</a>
					</li>
					
				</ul>
			</nav>
		</div>
	</div>
</header>

			
	<div class="banner">
	
		
			<h1 style="color: $bannerNoImageColour">Meta-analysis for biologists using MCMCglmm</h1>
			
				<h3 style="color: $bannerNoImageColour">An introduction to the MCMCglmm package</h3>
			
		
	
</div>




<div class="content">
	<p class="author">
		
			Created by Kat
		
		
		
	</p>
	<hr>
	<p>This tutorial is aimed at people who are new to meta-analysis and using the <code class="language-plaintext highlighter-rouge">MCMCglmm</code> package written by <a href="https://www.youtube.com/watch?v=XepXtl9YKwc" target="_blank" rel="noopener noreferrer">Dr. Jarrod Hadfield</a>, to help you become comfortable with using the package, and learn some of the ways you can analyse your data. It isn’t designed to teach you about hardcore Bayesian statistics or mixed modelling, but rather to highlight the differences between MCMCglmm and other statistical approaches you may have used before, and overcome some of the problems you may encounter as a new user.</p>

<p>You’ll find the resources for the tutorial __<a href="https://github.com/ourcodingclub/CC-MCMCglmm-MA" target="_blank" rel="noopener noreferrer">in this repository</a>. Click on <code class="language-plaintext highlighter-rouge">Clone/Download/Download Zip</code> and then unzip the folder.</p>

<p>Don’t worry if you leave this tutorial feeling like you haven’t grasped key concepts. It will probably take practice and time to get to grips with all of this!</p>

<p>First we will learn a little about how <code class="language-plaintext highlighter-rouge">MCMCglmm</code> works. Then we’ll explore some <strong>syntax</strong>, get a <strong>model</strong> up and running, learn how to make sure it has run correctly and interpret the results. Then we’ll move on to things that are a little more complicated, and <strong><a href="https://www.youtube.com/watch?v=o7lilfpZNGc" target="_blank" rel="noopener noreferrer">this might happen</a></strong>.</p>

<p>Before we begin, you may like to check out the following links, which will help you understand a bit more about Bayesian statistics so you can hit the ground running in the tutorial.</p>

<p><strong><a href="https://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english" target="_blank" rel="noopener noreferrer">This link</a></strong> gives a quick description of the difference between <strong>Bayesian</strong> and <strong>frequentist</strong> statistics. <strong><a href="https://www.theregister.co.uk/2017/06/22/bayesian_vs_frequentist_ai/" target="_blank" rel="noopener noreferrer">This link</a></strong> does too, and is about zombies. You don’t need to become a Bayesian statistician to use <code class="language-plaintext highlighter-rouge">MCMCglmm</code>, but it will be <strong>VERY USEFUL</strong> to understand the difference when thinking about how the package works. If you are really into learning more <strong><a href="https://www.youtube.com/watch?v=U1HbB0ATZ_A&amp;index=1&amp;list=PLFDbGp5YzjqXQ4oE4w9GVWdiokWB9gEpm" target="_blank" rel="noopener noreferrer">these YouTube tutorials</a></strong> will take a bit more time, but are well laid out.</p>

<p>I would also strongly recommend having a copy of the <strong><a href="https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf" target="_blank" rel="noopener noreferrer">MCMCglmm course notes</a></strong> open and ready to refer back to whenever something new comes up. They’ll explain concepts statistically, whereas I may gloss over some things in order to try making things a little easier when learning about them <em>for the first time</em>.</p>

<h3 id="tutorial-aims">Tutorial Aims:</h3>

<ol>
  <li><a href="#metaanalysis">Understanding what a meta-analysis is</a></li>
  <li><a href="#mcmcglmm">Understanding what MCMCglmm is and why you might want to use it</a></li>
  <li><a href="#effects">Learning the difference between fixed versus random effects meta-analyses and an introduction to variance</a></li>
  <li><a href="#syntax">Becoming familiar with the syntax and model output</a></li>
  <li><a href="#priors">Learning what a prior is, and the (absolute) basics on how they work</a></li>
  <li><a href="#parameter">Understanding parameter expanded priors and measurement error</a></li>
  <li><a href="#extras">Extras: fixed effects, posterior mode (BLUPs), Calculating 95% Credible Intervals, non-Gaussian families, (co)variance structures</a></li>
</ol>

<h2 id="metaanalysis">1. Understanding what a meta-analysis is</h2>

<h4 id="a-meta-analysis-is-a-statistical-analysis-of-results-from-many-individual-studies-on-similar-subjects-it-provides-a-much-more-robust-estimate-than-each-individual-study-alone-it-can-also-reveal-patterns-and-trends-across-studies-as-it-allows-them-to-be-compared-while-controlling-for-sources-of-non-independence-and-measurement-error-inherent-in-individual-studies">A meta-analysis is a statistical analysis of results from many individual studies on similar subjects. It provides a much more robust estimate than each individual study alone. It can also reveal patterns and trends across studies, as it allows them to be compared while controlling for sources of <em>non-independence</em> and <em>measurement error</em> inherent in individual studies.</h4>

<p>Comparing studies from different <strong>locations</strong> (e.g. latitude, elevation, hemisphere, climate zone), across <strong>different species</strong> (e.g. with different behaviours or life history traits) or <strong>time periods</strong> (e.g. when the study was done and how long it lasted) introduce sources of <em>non-independence</em> which need to be controlled for when estimating an average effect across all studies.</p>

<p>However, these sources of non-independence may be of interest to us; for example, perhaps in controlling for latitude, we also discover it explains a large proportion of the variance across studies in the response we are looking at. We can then say that latitude is a good predictor of this response.</p>

<h4 id="as-biologists-we-are-often-looking-for-predictors-such-as-the-locational-differences-species-or-time-periods-mentioned-above-of-how-organisms-respond-to-different-treatments-or-in-environments-etc">As biologists, we are often looking for predictors (such as the locational differences, species, or time periods mentioned above) of how organisms respond to different treatments, or in environments etc.</h4>

<h4 id="a-meta-analysis-is-a-great-way-to-do-this">A meta-analysis is a great way to do this.</h4>

<p>Often results used in a meta-analysis have come from previously published studies. This workshop is aimed at teaching you <strong>what to do once you have collected your data</strong>, although the dataset we will use is a good example of one used in a meta-analysis.</p>

<p>To learn more about how to conduct a systematic review (the pre-cursor to a meta-analysis) check out this: <strong><a href="http://www.prisma-statement.org" target="_blank" rel="noopener noreferrer">http://www.prisma-statement.org/</a></strong>.  Before continuing with your own meta-analysis, <strong><a href="https://doi.org/10.1186/s12915-017-0357-7" target="_blank" rel="noopener noreferrer">this paper</a></strong> offers some good advice on what makes a good one.</p>

<p>For now, let’s move on to the next step…</p>

<h2 id="mcmcglmm">2. Understanding what MCMCglmm is and why you might want to use it</h2>

<h4 id="mcmcglmm-fits-generalised-linear-mixed-effects-models-using-a-markov-chain-monte-carlo-approach-under-a-bayesian-statistical-framework-if-some-or-all-of-those-things-make-no-sense-to-you-dont-worry--you-can-still-use-mcmcglmm-without-understanding-all-of-this">
<code class="language-plaintext highlighter-rouge">MCMCglmm</code> fits <em>Generalised Linear Mixed-effects Models</em> using a <em>Markov chain Monte Carlo</em> approach under a <em>Bayesian statistical framework</em>. If some or all of those things make no sense to you, don’t worry – you can still use <code class="language-plaintext highlighter-rouge">MCMCglmm</code> without understanding all of this.</h4>

<p>Bayesian statistics sounds scary, but actually it’s more intuitive to understand (in my opinion) than frequentist statistics.</p>

<p>For example, if I had a coin and asked what is the probability of flipping a head you would say 0.5. This would be the frequency of heads if you flipped the coin a large number of times. This is the basis of <strong>frequentist statistics</strong>: the probability of observing the data conditional on a set of parameter values. This probability is equal to the frequency at which a particular set of data would be observed had the experiment been run (hypothetically) a very large number of times.</p>

<p>Alternatively, if I had already flipped the coin but did not let you see it, and asked the same question you would still say 0.5.  But this is different - the coin is already flipped and it is either a head or a tail with probability zero or one. You have stated 0.5 because you don’t know what actually happened during the coin flip. This is the basis of <strong>Bayesian statistics</strong>: there is a true parameter value out there but you don’t know what it is.</p>

<p>Bayesian statistics therefore considers the probability of a set of parameter values conditional on observing the data. This probability is characterising subjective uncertainty about the true values.</p>

<p><strong>In other words, frequentist statistics relies on you sampling the population enough times until you get a true value, but this value can change depending on the number of times you sample from the distribution i.e. data you use can change but you don’t change the parameters in your model. Whereas with Bayesian stats you know there can only be one true distribution regardless of how many times you sample from it, and instead you use your understanding of the system to influence the parameters you choose to describe this distribution in your model, i.e. the data don’t change, it’s your model that changes.</strong></p>

<p>Furthermore, with <strong>Bayesian statistics</strong>, we include prior probabilities in our models, based on our knowledge of previous situations. In this case, the data are fixed and the parameters are what we change, depending on our prior knowledge, and whether we think it’s likely that a certain outcome will happen.</p>

<p>Take a look at this schematic of Bayes’ theorem. The output of a <code class="language-plaintext highlighter-rouge">MCMCglmm</code> model is a <strong>posterior distribution</strong>, which is a combination of your data, your prior knowledge, and the <strong><a href="https://www.youtube.com/watch?v=XepXtl9YKwc" target="_blank" rel="noopener noreferrer">likelihood</a></strong> function.</p>

<p><img src="/assets/img/tutorials/mcmcglmm/mcmc1Bayes.PNG" alt=""></p>

<p>More info on <strong>GLMMs</strong> in <strong><a href="https://www.sciencedirect.com/science/article/pii/S0169534709000196" target="_blank" rel="noopener noreferrer">this paper</a></strong> . MCMC is a bit more complicated to explain. Most simply put, it’s an algorithm which can draw random samples from a posterior distribution so that we can explore its characteristics. If you would like to understand a bit more about how <strong><a href="https://theclevermachine.wordpress.com/2012/09/24/a-brief-introduction-to-markov-chains/" target="_blank" rel="noopener noreferrer">Markov chain</a></strong> <strong><a href="https://theclevermachine.wordpress.com/2012/09/22/monte-carlo-approximations/" target="_blank" rel="noopener noreferrer">Monte Carlo</a></strong> algorithms work, check out these links, and <strong><a href="http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/" target="_blank" rel="noopener noreferrer">this one</a></strong>.</p>

<p>Today we are going to focus on using <code class="language-plaintext highlighter-rouge">MCMCglmm</code> for <strong>meta-analysis</strong>. The two key reasons why <code class="language-plaintext highlighter-rouge">MCMCglmm</code> is so good for this is because you can control for <strong>phylogeny</strong> (which is a source of non-independence like we mentioned before), and also <strong>measurement error</strong>.</p>

<h2 id="effects">3. Learning the difference between fixed versus random effects meta-analyses and an introduction to variance</h2>

<h4 id="in-this-section-we-are-going-to-consider-the-difference-between-a-fixed-and-random-effects-meta-analysis-this-is-different-to-considering-the-difference-between-fixed-and-random-effects-although-you-may-learn-a-little-bit-about-the-difference-between-these-too-as-the-glmm-part-of-mcmcglmm-would-suggest-you-can-also-use-the-package-for-mixed-effects-meta-analyses">In this section we are going to consider the difference between a fixed and random effects <em>meta-analysis</em>. This is different to considering the difference between fixed and random <em>effects</em>, although you may learn a little bit about the difference between these, too. As the <code class="language-plaintext highlighter-rouge">glmm</code> part of <code class="language-plaintext highlighter-rouge">MCMCglmm</code> would suggest, you can also use the package for <em>mixed-effects meta-analyses</em>.</h4>

<p>There is no fundamental distinction between (what we call) fixed effects and random effects in a Bayesian analysis. The key is in understanding how each type of analysis deals with <strong><em>variance</em></strong>.</p>

<p><img src="/assets/img/tutorials/mcmcglmm/mcmc2fixed.png" alt=""></p>

<p>In these funnel plots, each data point represents a response (slope of change in timing of arrival of birds at their breeding grounds in days/year) from a previously published study. We use 1/SE as a measure of precision. Data points estimated with high standard error will have low precision, and gather towards the bottom of the plot. Vice versa with those estimated with low standard error. Thus, points with low standard error (high precision) should funnel in around the true effect size.</p>

<p><strong>Fixed effect meta-analyses</strong> assume that any between-observation variance is due to sampling error alone (such that the funnel plot goes to a point as the precision goes to infinity). They are particularly useful when combining experimental studies. For example, <strong><em>do males or females respond more effectively to a treatment</em></strong>? In a meta-analysis of lots of treatments of individuals, we may include sex as a <strong>fixed effect</strong> because we want a definitive answer to this question.</p>

<p>When we treat an effect as fixed, we believe that knowledge of other effects does not provide information on the likely magnitude of our focal effect. For example, imagine we had five treatments and a control. If we knew that four of the five treatments changed the response by less than 10% then we would not use this information to down weight estimates of the fifth treatment that were more extreme.</p>

<p>With <strong>random effects meta-analyses</strong>, we do use this information: sampling error is likely to contribute to extreme estimates and so they should be trusted less, i.e. given less <em>statistical weight</em>.
Furthermore, some of the between observation variance is allowed to be real and is estimated. This is particularly useful when asking questions with data from wild systems, where we would assume there is natural variation, and we want to find patterns that might help us explain it.</p>

<p>For example, let’s say we want to know whether migratory birds arrive at their breeding grounds at roughly the same time of year as they did in past decades, or if they now arrive earlier or later as a result of changing climates. We have collected data from many different published studies reporting the number of days earlier or later birds arrive in days/year and days/degree Celsius. This global meta-dataset includes data from many different species, countries, latitudes etc.</p>

<p>We’ll be using a dataset that contains this information. You’ve already downloaded the dataset <code class="language-plaintext highlighter-rouge">migration_metadata.csv</code>  from <a href="https://github.com/ourcodingclub/CC-MCMCglmm-MA" target="_blank" rel="noopener noreferrer">this repository</a>, so you can import it into R to have a look. The data come from this elegant <strong><a href="http://onlinelibrary.wiley.com/doi/10.1111/1365-2656.12612/full" target="_blank" rel="noopener noreferrer">meta-analysis of changes in timing of bird migration</a></strong>.</p>

<p>Using a meta-analysis we can calculate the average number of days’ difference across all populations for which we have data using the intercept as our only fixed effect. But, we would assume that there will be a huge amount of variation around this average response, and we want to figure out if we can find any patterns in it, maybe across species, locations or life history traits.</p>

<p>Including species as a random effect will tell us how much variance there is between species. It will also estimate an average response for each, however, it is usually more informative to report the variance between species, rather than the effect of each species separately. In this respect, you might choose to include something as a random effect when there are <strong>lots of categories</strong> (in this case there are lots of species) in your variable, so that you can report the <em>variance</em>.</p>

<h2 id="syntax">4. Becoming familiar with the syntax and model output</h2>

<p>To get started, download the data, import it into R and load packages. Set your working directory to the folder where you downloaded the files by either running the code <code class="language-plaintext highlighter-rouge">setwd("your-filepath")"</code> where you swap <code class="language-plaintext highlighter-rouge">your-filepath</code> with your actual filepath, or you can click on <code class="language-plaintext highlighter-rouge">Session/Set working directory/Choose directory</code> and navigate to your folder. Afterwards you’ll see the code for this appear in the console, you can copy that into your script, so that in the future you know where the data are.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load packages</span><span class="w">

</span><span class="n">library</span><span class="p">(</span><span class="s2">"MCMCglmm"</span><span class="p">)</span><span class="w"> </span><span class="c1"># for meta-analysis</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"dplyr"</span><span class="p">)</span><span class="w"> </span><span class="c1"># for data manipulation</span><span class="w">

</span><span class="n">migrationdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"migration_metadata.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w"> </span><span class="c1"># import dataset</span><span class="w">
</span><span class="n">View</span><span class="p">(</span><span class="n">migrationdata</span><span class="p">)</span><span class="w"> </span><span class="c1"># have a look at the dataset. Check out the Predictor variable. There are two, time and temperature.</span><span class="w">
</span></code></pre></div></div>

<p>Have a look at the dataset. Check out the Predictor variable. There are two, time and temperature. For the first part of the tutorial, let’s just look at rows where <strong><em>annual arrival date has been measured over time</em></strong>. To try things on your own afterwards, try replacing time with temperature and following the steps below.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">migrationdata</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
</span><span class="n">filter</span><span class="p">(</span><span class="n">Predictor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"year"</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">migrationtime</span><span class="w"> </span><span class="c1"># this reduces the dataset to one predictor variable, time.</span><span class="w">
</span></code></pre></div></div>

<p>Before we start, let’s plot the data. A <strong>funnel plot</strong> is typically used to visualize data for meta-analyses. This is done by plotting the predictor variable against <code class="language-plaintext highlighter-rouge">1/standard error</code> for each data point. This weights each study in the plot by its precision, ultimately giving less weight to studies with high standard error. In this case, <code class="language-plaintext highlighter-rouge">Slope</code> is change in arrival date in days/year.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">Slope</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">SE</span><span class="p">))</span><span class="w"> </span><span class="c1"># this makes the funnel plot of slope (rate of change in days/year) and precision (1/SE)</span><span class="w">

</span></code></pre></div></div>
<p><img src="/assets/img/tutorials/mcmcglmm/funnel.png" alt=""></p>

<p>You can see here that the data seem to funnel in around zero, and that both positive and negative values are well represented, i.e. this study does not suffer from <strong>publication bias</strong>.
Let’s look at the plot again, with a more zoomed in view.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">Slope</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">SE</span><span class="p">),</span><span class="w"> </span><span class="n">xlim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-2</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">60</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/funnel_zoom.png" alt=""></p>

<p>Now, we can see in more detail that the true value seems to funnel in just left of zero, and there is quite a lot of variation around this. <strong>Understanding how the data look is a good place to start.</strong></p>

<p>Now we’ll run a <strong><em>random effects model</em></strong>, with only the intercept as a fixed effect. The intercept is going to estimate the average change in arrival date across all data points. There are lots of different species, locations and studies in this analysis, and so the random effects are going to estimate whether there is true variation around the intercept and how much of it can be explained by an effect of species, location, or study.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">randomtest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">randomtest</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>We now have a distribution of estimated parameters, because <code class="language-plaintext highlighter-rouge">MCMCglmm</code> has run through 13,000 iterations of the model and sampled 1000 of them to provide a <strong>posterior distribution</strong>.</p>

<p>Let’s look at our summary statistics, <code class="language-plaintext highlighter-rouge">summary(randomtest)</code>. The summary shows us a <em>posterior mean</em> for each effect, <em>upper</em> and <em>lower 95% Credible Intervals</em> (not Confidence Intervals) of the distribution, <em>effective sample size</em> and for the fixed effects, a <em>pMCMC value</em>.</p>

<p>Your effective sample size should be quite high <strong>(I usually aim for 1000-2000)</strong>. More complicated models often require more iterations to achieve a comparable effective  sample size.</p>

<h3 id="assessing-significance">Assessing significance</h3>

<p>We can accept that a <strong>fixed effect</strong> is significant when the credible intervals <strong>do not span zero</strong>, this is because if the posterior distribution spans zero, we cannot be confident <strong>that it is not zero</strong>. While a <code class="language-plaintext highlighter-rouge">pMCMC</code> value <em>is</em> reported, it’s better to pay more attention to the credible intervals. Ideally your posterior distribution will also be narrow indicating that that parameter value is known precisely. Here’s an example of a poorly and a well estimated posterior distribution. The red line represents the posterior mean in both cases.</p>

<p><img src="/assets/img/tutorials/mcmcglmm/Image%206.PNG" alt=""></p>

<p>With <strong>random effects</strong>, we estimate the variance. As variance cannot be zero or negative, we accept that a random effect is significant when the distribution of the variance is not pushed up against zero. To check this, we can plot the histogram of each posterior distribution.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot the posterior distribution as a histogram to check for significance and whether it's been well estimated or not</span><span class="w">
</span><span class="c1"># Variance cannot be zero, and therefore if the mean value is pushed up against zero your effect is not significant</span><span class="w">
</span><span class="c1"># The larger the spread of the histogram, the less well estimated the distribution is.</span><span class="w">

</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">))</span><span class="w">

</span><span class="n">hist</span><span class="p">(</span><span class="n">mcmc</span><span class="p">(</span><span class="n">randomtest</span><span class="o">$</span><span class="n">VCV</span><span class="p">)[,</span><span class="s2">"Study"</span><span class="p">])</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">mcmc</span><span class="p">(</span><span class="n">randomtest</span><span class="o">$</span><span class="n">VCV</span><span class="p">)[,</span><span class="s2">"Location"</span><span class="p">])</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">mcmc</span><span class="p">(</span><span class="n">randomtest</span><span class="o">$</span><span class="n">VCV</span><span class="p">)[,</span><span class="s2">"Species"</span><span class="p">])</span><span class="w">

</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w"> </span><span class="c1"># Reset the plot panel back to single plots</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/histograms.png" alt=""></p>

<p>Here we can see that the distribution of variance for Location and Species is pressed right up against zero. For a random effect to be significant, we want the tails to be well removed from zero.</p>

<h3 id="assessing-model-convergence">Assessing model convergence</h3>

<p>Now let’s check for model convergence. We do this separately for both fixed and random effects.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">randomtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">)</span><span class="w">

</span></code></pre></div></div>
<p><img src="/assets/img/tutorials/mcmcglmm/sol.png" alt=""></p>

<p>Here you can see the trace and density estimate for the intercept. The trace is like a time series of what your model did while it was running and can be used to assess mixing (or convergence), while the density is like a smoothed histogram of the estimates of the posterior distribution that the model produced for every iteration of the model.</p>

<h3 id="to-make-sure-your-model-has-converged-the-trace-plot-should-look-like-a-fuzzy-caterpillar-it-looks-like-the-intercept-has-mixed-well">To make sure your model has converged, the trace plot should look like a fuzzy caterpillar. It looks like the intercept has mixed well.</h3>

<p>If you suspect too much autocorrelation there are a few things you can do.</p>

<p><strong>1)</strong> Increase the number of iterations, default is <code class="language-plaintext highlighter-rouge">13000</code> (e.g. <code class="language-plaintext highlighter-rouge">nitt = 60000</code>, I often use hundreds of thousands of iterations for more complex models)</p>

<p><strong>2)</strong> Increase the burn in, the default here is that <code class="language-plaintext highlighter-rouge">MCMCglmm</code> will discount the first 3000 iterations which aren’t as accurate as the model hasn’t converged yet, you can increase this (e.g. <code class="language-plaintext highlighter-rouge">burnin = 5000</code>)</p>

<p><strong>3)</strong> Increase the thinning interval, the default is 10 (e.g. <code class="language-plaintext highlighter-rouge">thin = 30</code>)</p>

<p><strong>4)</strong> Think about using a stronger prior, but more on that in a little while.</p>

<p><strong>Note from Jarrod:</strong> In a Markov chain the value at time t is independent of the value at time t-2, <em>conditional</em> on the value at time t-1. This does not mean that each iteration should be independent of the past one; in fact they will be autocorrelated (except in the simplest analyses). You don’t have to ensure stored samples are independent - the key thing is that for the same number of iterations an autocorrelated sample contains less information than a correlated sample. If you want to store a set number of samples (because you don’t want to use your hard drive up) you are then better increasing the thinning interval so the samples you have collected are less correlated.</p>

<p>For more on diagnostics check this link out: <strong><a href="http://sbfnk.github.io/mfiidd/mcmc_diagnostics.html" target="_blank" rel="noopener noreferrer">http://sbfnk.github.io/mfiidd/mcmc_diagnostics.html</a></strong>.</p>

<p>Let’s do the same thing now, but for the variances of the random effects. Depending on your laptop and screen, you may get an error message saying that the plots are too big to display - you can make your plot panel bigger by dragging it upwards and towards the left, then your plots will have enough space to appear.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">randomtest</span><span class="o">$</span><span class="n">VCV</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/randomtest_traces.png" alt=""></p>

<p>It looks like some of the variances of the random effects haven’t mixed very well at all. The effective sample size is also very small. Maybe we could improve this by increasing the number of iterations, but because the chain seems to be stuck around zero, it looks like <strong><em>we’ll need to use a stronger prior</em></strong> than the default.</p>

<p>You can find more information about this in Chapter 8 of the <strong><a href="https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf" target="_blank" rel="noopener noreferrer">MCMCglmm course notes</a></strong>.</p>

<h2 id="priors">5. Learning what a prior is, and the (absolute) basics on how they work</h2>

<h4 id="the-most-difficult-part-of-a-bayesian-analysis-to-understand-is-how-to-fit-correct-priors">The most difficult part of a Bayesian analysis to understand is how to fit <strong>correct priors</strong>.</h4>

<p>These are mathematical quantifications of our prior knowledge of what we think the mean and/or variance of a parameter might be. We fit a separate prior for each fixed and random effect, and for the residual.</p>

<p>We can thus use priors to inform the model which shape we think the posterior distribution will take.
In the schematic below, you can see we use our prior beliefs to “drag” the distribution of our likely parameter values towards the left.</p>

<p><img src="/assets/img/tutorials/mcmcglmm/mcmc4priorposterior.png" alt=""></p>

<p>It’s very difficult to understand how the prior interacts with the distribution of the data and the likelihood function to give the posterior distribution. That’s why we need complex algorithms like MCMC. However, it’s very difficult to be confident that you have done this correctly, and a key reason why Bayesian statistics can be confusing.</p>

<p>Firstly, priors can vary in how informative they are. <strong>Weakly informative</strong> priors should be used in situations where we don’t have much prior knowledge and want the data to speak for themselves. The prior won’t drag the posterior distribution away from the parameter values which the data suggest are likely. <strong>Informative</strong> priors provide information that is crucial to the estimation of the model, and will shape the posterior distribution quite a bit.</p>

<p>In MCMCglmm, each prior follows a similar formula and whether it is strongly or weakly informative depends on the values you include in it. <strong>Note from Jarrod:</strong> Priors don’t have to follow a similar formula: they do in MCMCglmm because only a few prior distributions are allowed for each type of parameter.</p>

<p>Be careful when you read that a prior is <strong>uninformative</strong>; there is no such thing as a completely uninformative prior, but explaining why is beyond what’s necessary for this tutorial.</p>

<p><img src="/assets/img/tutorials/mcmcglmm/mcmc5priorstrength.png" alt=""></p>

<p>With <code class="language-plaintext highlighter-rouge">MCMCglmm</code>, the default prior assumes a normal posterior distribution with very large variance for the fixed effects and a flat improper (weakly informative) prior. For the variances of the random effects, inverse-Wishart priors are implemented. An inverse-Wishart prior contains your variance matrix <em>V</em>, and your degree of believe parameter, <code class="language-plaintext highlighter-rouge">nu</code>.</p>

<p>Below you can see what an inverse Wishart prior looks like in graphical terms. You can see that <code class="language-plaintext highlighter-rouge">nu</code> can vary in its strength and level of information. Imagine what each level of <code class="language-plaintext highlighter-rouge">nu</code> might do to your data - we might expect that when <code class="language-plaintext highlighter-rouge">nu</code> is low, it will be less informative, except for the lowest values of your distribution, which it might drag leftwards slightly.</p>

<p><img src="/assets/img/tutorials/mcmcglmm/mcmc6nu.PNG" alt=""></p>

<p>The more complicated your models become, the more likely it is that you will eventually get an error message, or as we have just seen, that your models will not mix from the beginning. In this case we should use <strong>parameter expanded priors</strong> of our own. The use of parameter expansion means the priors are no longer inverse-Wishart but scaled-F (don’t worry if you don’t understand this!). This is not neceassrily a bad thing, as parameter expanded priors are less easy to specify incorrectly than inverse-Wishart priors.</p>

<p><strong>However, proceed with caution from this point on!</strong></p>

<h2 id="parameter">6. Understanding parameter expanded priors and measurement error</h2>

<h4 id="lets-run-the-model-again-but-this-time-well-use-parameter-expanded-priors-for-the-random-effects-by-including-prior--prior1-each-random-effect-is-represented-by-a-g-and-the-residual-is-represented-by-r-the-parameter-expansion-refers-to-the-fact-that-we-have-included-a-prior-mean-alphamu-and-covariance-matrix-alphav-as-well-as-v-and-nu-for-now-alphav-is-going-to-be-1000-but-you-can-lean-more-about-other-variance-structures-in-section-7-of-this-tutorial-and-in-the-mcmcglmm-course-notes-too">Let’s run the model again, but this time we’ll use <strong>parameter expanded priors</strong> for the random effects by including <code class="language-plaintext highlighter-rouge">prior = prior1</code>. Each random effect is represented by a G, and the residual is represented by R. The parameter expansion refers to the fact that we have included a prior mean (<code class="language-plaintext highlighter-rouge">alpha.mu</code>) and (co)variance matrix (<code class="language-plaintext highlighter-rouge">alpha.V</code>) as well as <code class="language-plaintext highlighter-rouge">V</code> and <code class="language-plaintext highlighter-rouge">nu</code>. For now, <code class="language-plaintext highlighter-rouge">alpha.V</code> is going to be 1000, but you can lean more about other variance structures in section 7 of this tutorial, and in the <strong><a href="https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf" target="_blank" rel="noopener noreferrer">MCMCglmm course notes</a></strong>, too.</h4>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span><span class="w">
</span><span class="n">prior1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.002</span><span class="p">),</span><span class="w">
               </span><span class="n">G</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">)))</span><span class="w">

</span><span class="n">randomprior</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="p">,</span><span class="w"> 
                        </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">,</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior1</span><span class="p">,</span><span class="w"> </span><span class="n">nitt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">60000</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><strong>Note:</strong> I have increased the number of iterations as 60000 to improve mixing and effective sample sizes.</p>

<p><strong>Another note:</strong> I haven’t printed any summary statistics to show in this tutorial. Because of the stochastic nature of MCMC, every time you (re)run a model, your output will be slightly different, so even if you use the same effects in your model, it would always be slightly different to whatever was printed here.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">summary</span><span class="p">(</span><span class="n">randomprior</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>The effective sample sizes are much bigger now! This is a good sign.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">randomprior</span><span class="o">$</span><span class="n">VCV</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/randomprior_traces.png" alt=""></p>

<p>The models look to have mixed much better too. This is also good.</p>

<p>Before we do our model checks, I want to control for <strong>sampling error</strong> in the model. This is one of the key reasons we would use <code class="language-plaintext highlighter-rouge">MCMCglmm</code> for meta-analysis over another programme or package. You can read the meta-analysis section of the course notes to understand more.</p>

<p>The key assumption of a meta-analysis is that the between observation variance due to sampling error can be approximated as the standard error squared. We can use a computational trick to allow this in MCMCglmm by fitting <code class="language-plaintext highlighter-rouge">idh(SE):units</code> as a random effect and fixing the associated variance at 1. You can see that we now have four random priors, the last of which is fixed at 1.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prior2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.002</span><span class="p">),</span><span class="w">
               </span><span class="n">G</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">fix</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)))</span><span class="w">

</span><span class="n">randomerror2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idh</span><span class="p">(</span><span class="n">SE</span><span class="p">)</span><span class="o">:</span><span class="n">units</span><span class="p">,</span><span class="w"> 
                         </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">,</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior2</span><span class="p">,</span><span class="w"> </span><span class="n">nitt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">60000</span><span class="p">)</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">randomerror2</span><span class="o">$</span><span class="n">VCV</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/randonerror_traces.png" alt=""></p>

<p><img src="/assets/img/tutorials/mcmcglmm/randomerror_traces2.png" alt=""></p>

<p>If you check the summary now, you can see that now we’ve included measurement error, our estimates are much more conserved. Studies with higher standard error have been given lower statistical weight.</p>

<p>Now, we’ll perform our model checks. To do this, we will simulate new data given the same parameter values (variance/co-variance structures (priors)), and then plot it against our real data to make sure they overlap. Remember that in Bayesian analyses, the data remain fixed and it’s the parameters that change. So if we have used the correct parameters, we should be able to use them to simulate new data that look like the original.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xsim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">simulate</span><span class="p">(</span><span class="n">randomerror2</span><span class="p">)</span><span class="w"> </span><span class="c1"># reruns 100 new models, based around the same variance/covariance structures but with simulated data.</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">Slope</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">SE</span><span class="p">))</span><span class="w">
</span><span class="n">points</span><span class="p">(</span><span class="n">xsim</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">SE</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="c1"># here you can plot the data from both your simulated and real datasets and compare them</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/sim_funnel1.png" alt=""></p>

<p>This seems to fit reasonably well, although the simulated data are perhaps skewed a bit too much towards the left.</p>

<p><strong>Note from Jarrod:</strong> The issue here is complicated - but let’s give it a try. The issue is that the sampling variance for low-precision estimates is actually higher than the SE^2 (i.e. the assumption of a meta-analysis is not met). This means a) too much weight is still put on low precision studies b) some of the biological variation (the units variance) is overestimated and c) if publication bias is more likely amongst low-precision studies then the mean effect size may be biased.</p>

<p>One quick solution is to see if the between observation variance increases more with the reported standard error faster than it should. To do this we can estimate the variance, rather than assume it is 1, and see if the estimate is greater than 1.</p>

<p>Let’s rerun the model, but this time changing the prior for measurement error so that it is no longer fixed at 1.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prior3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.002</span><span class="p">),</span><span class="w">
               </span><span class="n">G</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
                        </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">)))</span><span class="w">

</span><span class="n">randomerror3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idh</span><span class="p">(</span><span class="n">SE</span><span class="p">)</span><span class="o">:</span><span class="n">units</span><span class="p">,</span><span class="w"> 
                         </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">,</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior3</span><span class="p">,</span><span class="w"> </span><span class="n">nitt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">60000</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Now we can simulate new data again, and plot it against our collected data.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xsim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">simulate</span><span class="p">(</span><span class="n">randomerror3</span><span class="p">)</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">Slope</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">SE</span><span class="p">))</span><span class="w">
</span><span class="n">points</span><span class="p">(</span><span class="n">xsim</span><span class="p">,</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">SE</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="c1"># here you can plot the data from both your simulated and real datasets and compare them</span><span class="w">
</span></code></pre></div></div>

<p><img src="/assets/img/tutorials/mcmcglmm/sim_funnel2.png" alt=""></p>

<p>These parameters seem to be a better fit for our data.</p>

<p>Another trick for checking whether the parameters fit the data is to make sure your max (or min) values fit inside a histogram of your simulated distribution, like this:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xsim</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">simulate</span><span class="p">(</span><span class="n">randomerror3</span><span class="p">,</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="c1"># 1000 represents the number of simulations, and for some reason needs to be higher than the default to work in this case</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">apply</span><span class="p">(</span><span class="n">xsim</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">),</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot your simulation data</span><span class="w">

</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="n">migration</span><span class="o">$</span><span class="n">Slope</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="c1"># check to see whether the max value of your real data falls within this histogram.</span><span class="w">
</span></code></pre></div></div>

<p>Hopefully this has given you a good idea on how to get started with MCMCglmm!</p>

<h4 id="now-its-your-turn">Now it’s your turn!</h4>

<p><strong>1.</strong>	Filter the data by rows which have temperature as the predictor</p>

<p><strong>2.</strong>	Plot the data using a funnel plot</p>

<p><strong>3.</strong>	Run a basic random effects model. Save the posterior mode.</p>

<p><strong>4.</strong>	Plot VCV (random) and Sol (fixed) and check for autocorrelation</p>

<p><strong>5.</strong>	Increase the number of iterations and burn in, check your priors</p>

<p><strong>6.</strong>	Do model checks</p>

<p><strong>7.</strong>  Interpret your model!</p>

<p><strong>8.</strong>	After you read the next section, you might want to include some fixed effects, or use different variance structures for your residual as well.</p>

<h2 id="extra">7. Extras: fixed effects, posterior mode (BLUPs), non-gaussian families, (co)variance structures</h2>

<h3 id="fixed-effects">Fixed effects</h3>

<p>As well as random effects, you can also fit fixed effects. <code class="language-plaintext highlighter-rouge">MCMCglmm</code> estimates the random effects just like fixed effects, but with random effects meta-analyses, it is the <strong>variance</strong> that is usually the focus of the analysts interest.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fixedtest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Migration_distance</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Continent</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idh</span><span class="p">(</span><span class="n">SE</span><span class="p">)</span><span class="o">:</span><span class="n">units</span><span class="p">,</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior3</span><span class="p">,</span><span class="err">\</span><span class="w">                           </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">,</span><span class="w"> </span><span class="n">nitt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">60000</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p><strong>Note:</strong> I have never had to change the priors for a fixed effect, but this would be worth some research for your own projects.</p>

<h3 id="calculating-the-posterior-mean-of-the-random-effects-similar-to-best-linear-unbiased-predictors">Calculating the posterior mean of the random effects (similar to Best Linear Unbiased Predictors)</h3>

<p>I previously mentioned that <code class="language-plaintext highlighter-rouge">MCMCglmm</code> estimates both the <em>variance</em> of a random effect and the <em>true effect size</em> for each category within it, but that it is more informative to report the variance of the random effects than it is to report each effect size. When you use <code class="language-plaintext highlighter-rouge">summary()</code>, R will therefore report the variance and credible intervals of the random effects, but not the effect sizes. However, you can save the posterior mode of these effect sizes and report them in your work. You should <strong>never</strong> do further statistical analyses on them though, and always be sure to let your reader know that this is where your prediction has come from.</p>

<h4 id="why-arent-we-calling-them-best-linear-unbiased-predictors">Why aren’t we calling them Best Linear Unbiased Predictors?</h4>

<p><strong>Note from Jarrod:</strong> There is no fundemental difference between (what we call) fixed and random effects in a Bayesian analysis. However, in a Frequentist anlysis there is, and that’s why they use the words estimating and predicting. The distinction is not required when using <code class="language-plaintext highlighter-rouge">MCMCglmm</code>. BLUPS can be interpreted as the posterior mode of the random effects conditional on (RE)ML estimates of the variances. You can of course calculate the posterior modes of the random effects in <code class="language-plaintext highlighter-rouge">MCMCglmm</code>, but they are not BLUPS because we haven’t conditioned on the variances but averaged over their uncertianity.</p>

<p>To save the posterior mode of for each level or category in your random effect(s) we use <code class="language-plaintext highlighter-rouge">pr = TRUE</code>, which saves them in the <code class="language-plaintext highlighter-rouge">$Sol</code> part of the model output. Take a look:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fixedtest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Migration_distance</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Continent</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idh</span><span class="p">(</span><span class="n">SE</span><span class="p">)</span><span class="o">:</span><span class="n">units</span><span class="p">,</span><span class="w">
                      </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">,</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior3</span><span class="p">,</span><span class="w"> </span><span class="n">pr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">nitt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">60000</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Each random effect has a posterior distribution. The BLUP is <em>like</em> the mode of this posterior distribution.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posteriormode</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">mode</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>If we want to look at the posterior modes for Species, for example, we can choose the correct rows using the code below. This is a bit fiddly if you have lots of levels.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">names</span><span class="p">(</span><span class="n">posteriormode</span><span class="p">)</span><span class="w"> </span><span class="c1"># identify which posterior modes belong to Species</span><span class="w">
</span><span class="n">posteriormode</span><span class="p">[</span><span class="m">9</span><span class="o">:</span><span class="m">416</span><span class="p">]</span><span class="w"> </span><span class="c1"># there are a lot of species in this analysis!</span><span class="w">
</span></code></pre></div></div>

<p>This code will sort from smallest value to largest. Now you can report which species have been most or least responsive in changing their arrival date at breeding grounds.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sort</span><span class="p">(</span><span class="n">posteriormode</span><span class="p">[</span><span class="m">9</span><span class="o">:</span><span class="m">416</span><span class="p">])</span><span class="w">
</span></code></pre></div></div>

<h3 id="non-gaussian-families">Non-gaussian families</h3>

<p>This tutorial has been based around using a Gaussian distribution. However, <code class="language-plaintext highlighter-rouge">MCMCglmm</code> can handle non-Gaussian families as well. Specify <code class="language-plaintext highlighter-rouge">family=</code> to choose the correct distribution.</p>

<h3 id="calculating-95-credible-intervals">Calculating 95% Credible Intervals</h3>

<p>You may want to plot or report credible intervals from a model, without lifting the numbers straight from the summary. To do this you use <code class="language-plaintext highlighter-rouge">HPDinterval(mcmc())</code></p>

<p>Here’s an example:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HPDinterval</span><span class="p">(</span><span class="n">mcmc</span><span class="p">(</span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"(Intercept)"</span><span class="p">]))</span><span class="w">
</span></code></pre></div></div>

<p>This should look like similar values to the 95% Credible Intervals of the posterior distribution of your intercept when you look at the summary.</p>

<p><code class="language-plaintext highlighter-rouge">HPDinterval</code> is particularly useful when you want to combine effects. Say you want to know the mean and the upper &amp; lower 95% credible intervals of the posterior distribution of a short distance migrant from Europe. You can do that like this:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean</span><span class="p">(</span><span class="n">mcmc</span><span class="p">(</span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"(Intercept)"</span><span class="p">])</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"Migration_distanceshort"</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"ContinentEurope"</span><span class="p">])</span><span class="w">

</span><span class="n">HPDinterval</span><span class="p">(</span><span class="n">mcmc</span><span class="p">(</span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"(Intercept)"</span><span class="p">])</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"Migration_distanceshort"</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">fixedtest</span><span class="o">$</span><span class="n">Sol</span><span class="p">[,</span><span class="s2">"ContinentEurope"</span><span class="p">])</span><span class="w">
</span></code></pre></div></div>

<p>These values can then be used in plots, or reports etc.</p>

<h3 id="covariance-structures">(Co)variance structures</h3>

<p>Until now, we have learned that for each random effect and the residual in our model, <code class="language-plaintext highlighter-rouge">MCMCglmm</code> estimates the variance within that effect, i.e. the variance is in a 1x1 matrix - [<em>V</em>]. However, we can <strong>restructure the variance matrix</strong> within random effects and the residual if we want.</p>

<p>But why on earth would we want to do that? Here’s an example. In previous models, we have assumed that all measures of arrival date were the same, but actually, it has been measured in three different ways; first, mean and median dates of arrival. Peak arrival is included as a category here too, but there are no rows containing it.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">levels</span><span class="p">(</span><span class="n">migrationtime</span><span class="o">$</span><span class="n">Response_variable</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Our residual variance is therefore <strong>heterogeneous</strong>, and we need to take this into account in our model. We can do this by using the <code class="language-plaintext highlighter-rouge">idh():units</code> function in <code class="language-plaintext highlighter-rouge">rcov</code>.</p>

<p>Because we want to estimate the variance separately for each of these levels, we have to change the variance structure for the residual prior. In this case, we use a 3x3 variance matrix, because there are three types of response.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prior4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">R</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.002</span><span class="p">),</span><span class="w">
               </span><span class="n">G</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
               </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
	       </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
               </span><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">)))</span><span class="w">
</span></code></pre></div></div>

<p>If you just run <code class="language-plaintext highlighter-rouge">prior4</code> in your R console you should be able to visualise the matrix for the residual prior a bit more easily.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fixedtest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMCglmm</span><span class="p">(</span><span class="n">Slope</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Migration_distance</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Continent</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">Species</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Location</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Study</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">idh</span><span class="p">(</span><span class="n">SE</span><span class="p">)</span><span class="o">:</span><span class="n">units</span><span class="p">,</span><span class="w">
                      </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">migrationtime</span><span class="p">,</span><span class="w"> </span><span class="n">rcov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="n">idh</span><span class="p">(</span><span class="n">Response_variable</span><span class="p">)</span><span class="o">:</span><span class="n">units</span><span class="p">,</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">prior4</span><span class="p">,</span><span class="w"> </span><span class="n">pr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">nitt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">60000</span><span class="p">)</span><span class="w">

</span><span class="n">summary</span><span class="p">(</span><span class="n">fixedtest</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>Now we can see when we print the summary that the residual variance has now been estimated for all three measures of arrival. Success!</p>

<p><strong>Finally</strong>, as well as using variance matrices, you can use co-variance matrices, replacing <code class="language-plaintext highlighter-rouge">idh()</code> with <code class="language-plaintext highlighter-rouge">us()</code>. In this case, you will need to update the prior for your effect. If there are three levels, you need to increase the size of your matrix to 3, for example.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">G1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">nu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">alpha.mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">alpha.V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">3</span><span class="p">)</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="w">
</span></code></pre></div></div>

<p>However, I think this concept falls beyond the remit of an “introduction” to <code class="language-plaintext highlighter-rouge">MCMCglmm</code>. You can learn more about how to fit these matrices, and get some nice visualisations of what the matrices for each function look like in the “Compound Variance Structures” section of the Course Notes. Happy structuring!</p>


	<div class="survey">
	<hr>
	<hr>
	
		<h4><a href="" target="_blank">We would love to hear your feedback, please fill out our survey!</a></h4>
	
	<h4>Contact us with any questions on <a href="mailto:ourcodingclub@gmail.com?Subject=Tutorial%20question" target="_top">ourcodingclub@gmail.com</a>
</h4>
	<br>
	<h3>Related tutorials:</h3>
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
		
	
		
  			
		
	
		
  			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
	
		
  			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
    				
			
    				
			
    				
			
		
	
		
  			
		
	
		
  			
    				
			
		
	
	<br>
	<h3>Subscribe to our mailing list:</h3>

	<div class="container">
		<div class="block">
			<!-- subscribe form start -->
			<div class="form-group">
				<form action="https://getsimpleform.com/messages?form_api_token=de1ba2f2f947822946fb6e835437ec78" method="post">
					<div class="form-group">
						<input type="text" class="form-control" name="Email" placeholder="Email" required>
					</div>
					<div>
            			<button class="btn btn-default" type="submit">Subscribe</button>
        			</div>
            	</form>
			</div>
		</div>
	</div>
</div>

</div>

    	<footer class="footer">
	<hr>
	<div class="footer-container">
    	<ul class="footer-link-list">
        	<li><a href="/tutorials">Tutorials</a></li>
        	<li><a href="/team">About Us</a></li>
        	<li><a href="/contact">Contact us</a></li>
	    	<li><a href="https://twitter.com/our_codingclub" target="_blank" rel="noopener noreferrer">Follow us on Twitter</a></li>
    	</ul>
    	<div class="footer-text">
			<p>We are happy for people to use and further develop our tutorials - please give credit to Coding Club by linking to <a href="https://ourcodingclub.github.io/" target="_blank" rel="noopener noreferrer">our website</a>. We are also happy to discuss possible collaborations, so get in touch at <b>ourcodingclub@gmail.com</b></p>
    		<p>See our <a href="/terms">Terms of Use</a> and our <a href="/privacy">Data Privacy policy</a>.</p>
			<p>This work is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer">Creative Commons Attribution-ShareAlike 4.0 International License</a></p>
			<a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer"><img class="license" src="https://licensebuttons.net/l/by-sa/4.0/80x15.png" alt="CC-by-sa-4.0"></a>
    	</div>
    </div>
</footer>

<!-- JS -->
<script src="/scripts/owl.carousel.js"></script>
<script src="/scripts/owl.carousel-init.js"></script>
<script src="/scripts/reveal.js"></script>


	
	</body>
</html>
